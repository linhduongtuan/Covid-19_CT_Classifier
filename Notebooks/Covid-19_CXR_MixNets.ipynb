{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Covid-19', 'Normal', 'Pneumonia']\n",
      "{'train': 12884, 'val': 2758}\n",
      "cuda:1\n",
      "{0: 'Covid-19', 1: 'Normal', 2: 'Pneumonia'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/linh/Downloads/Covid-19/CXR_20200630'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/val'\n",
    "\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        ImageNetPolicy(),\n",
    "        Cutout(size=16),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "batch_size = 46\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4, pin_memory = True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['train'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['val']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 20, cat_to_name)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 20, cat_to_name)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mixnet_xl_ra-aac3c00c.pth\" to /home/linh/.cache/torch/checkpoints/mixnet_xl_ra-aac3c00c.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1536, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "#model = timm.create_model('resnet50', pretrained=True)\n",
    "model = timm.create_model('mixnet_xl', pretrained=True)\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "model.classifier #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of the model is: 14015611\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "fc = nn.Sequential(OrderedDict([('fc1', nn.Linear(1536, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, 3)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.fc = fc\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01,momentum=0.9,\n",
    "                      nesterov=True,\n",
    "                      weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=70, gamma=0.1)\n",
    "#show our model architechture and send to GPU\n",
    "model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "   \n",
    "    # Tensorboard summary\n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Record training loss and accuracy for each phase\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            else:\n",
    "                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            # deep copy the model\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record ACC: {epoch_acc}, previous record acc: {best_acc}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record acc is SAVED: {epoch_acc}')\n",
    "\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded\n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.63883612 Acc: 0.78143434\n",
      "val Loss: 0.29294721 Acc: 0.89303843\n",
      "New best model found!\n",
      "New record ACC: 0.8930384336475707, previous record acc: 0.0\n",
      "New record acc is SAVED: 0.8930384336475707\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.40673747 Acc: 0.83941323\n",
      "val Loss: 0.25563320 Acc: 0.90971719\n",
      "New best model found!\n",
      "New record ACC: 0.9097171863669326, previous record acc: 0.8930384336475707\n",
      "New record acc is SAVED: 0.9097171863669326\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.35593455 Acc: 0.86199938\n",
      "val Loss: 0.24625416 Acc: 0.91443075\n",
      "New best model found!\n",
      "New record ACC: 0.9144307469180566, previous record acc: 0.9097171863669326\n",
      "New record acc is SAVED: 0.9144307469180566\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.33291012 Acc: 0.87139087\n",
      "val Loss: 0.24390305 Acc: 0.90862944\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.31638008 Acc: 0.88287799\n",
      "val Loss: 0.20834147 Acc: 0.92603336\n",
      "New best model found!\n",
      "New record ACC: 0.9260333575054388, previous record acc: 0.9144307469180566\n",
      "New record acc is SAVED: 0.9260333575054388\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.29400761 Acc: 0.88551692\n",
      "val Loss: 0.19968719 Acc: 0.92784627\n",
      "New best model found!\n",
      "New record ACC: 0.9278462654097173, previous record acc: 0.9260333575054388\n",
      "New record acc is SAVED: 0.9278462654097173\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.28792095 Acc: 0.88846631\n",
      "val Loss: 0.21395744 Acc: 0.93437273\n",
      "New best model found!\n",
      "New record ACC: 0.9343727338651197, previous record acc: 0.9278462654097173\n",
      "New record acc is SAVED: 0.9343727338651197\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.28148121 Acc: 0.89273518\n",
      "val Loss: 0.18463736 Acc: 0.93074692\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.27603644 Acc: 0.89428749\n",
      "val Loss: 0.16950757 Acc: 0.93763597\n",
      "New best model found!\n",
      "New record ACC: 0.9376359680928209, previous record acc: 0.9343727338651197\n",
      "New record acc is SAVED: 0.9376359680928209\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.26967274 Acc: 0.89809066\n",
      "val Loss: 0.17496561 Acc: 0.94089920\n",
      "New best model found!\n",
      "New record ACC: 0.9408992023205222, previous record acc: 0.9376359680928209\n",
      "New record acc is SAVED: 0.9408992023205222\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.26426062 Acc: 0.89684880\n",
      "val Loss: 0.22170313 Acc: 0.92567078\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.25871172 Acc: 0.90065197\n",
      "val Loss: 0.18369174 Acc: 0.93763597\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.25176938 Acc: 0.90383421\n",
      "val Loss: 0.17584388 Acc: 0.93981146\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.24826671 Acc: 0.90468799\n",
      "val Loss: 0.17266641 Acc: 0.94343727\n",
      "New best model found!\n",
      "New record ACC: 0.943437273386512, previous record acc: 0.9408992023205222\n",
      "New record acc is SAVED: 0.943437273386512\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.24775093 Acc: 0.90732692\n",
      "val Loss: 0.16488680 Acc: 0.94597534\n",
      "New best model found!\n",
      "New record ACC: 0.9459753444525019, previous record acc: 0.943437273386512\n",
      "New record acc is SAVED: 0.9459753444525019\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.24149254 Acc: 0.91019870\n",
      "val Loss: 0.20902014 Acc: 0.93981146\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.24904961 Acc: 0.90600745\n",
      "val Loss: 0.18569844 Acc: 0.94053662\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.23050171 Acc: 0.91400186\n",
      "val Loss: 0.16632180 Acc: 0.94053662\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.24442551 Acc: 0.90965539\n",
      "val Loss: 0.17660812 Acc: 0.93836113\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.22055501 Acc: 0.91842595\n",
      "val Loss: 0.16376984 Acc: 0.94488760\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.22198157 Acc: 0.91764980\n",
      "val Loss: 0.17256264 Acc: 0.94561276\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.21735515 Acc: 0.91896926\n",
      "val Loss: 0.16344959 Acc: 0.94851342\n",
      "New best model found!\n",
      "New record ACC: 0.9485134155184917, previous record acc: 0.9459753444525019\n",
      "New record acc is SAVED: 0.9485134155184917\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.22034665 Acc: 0.91764980\n",
      "val Loss: 0.17389658 Acc: 0.94633793\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.20782847 Acc: 0.91904688\n",
      "val Loss: 0.16181316 Acc: 0.94379985\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.20932555 Acc: 0.91982304\n",
      "val Loss: 0.17324117 Acc: 0.94053662\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.20263096 Acc: 0.92215151\n",
      "val Loss: 0.18325422 Acc: 0.94162437\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.20888631 Acc: 0.92137535\n",
      "val Loss: 0.17296384 Acc: 0.94706309\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.20271393 Acc: 0.92354859\n",
      "val Loss: 0.17142722 Acc: 0.94416244\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.20270357 Acc: 0.92517852\n",
      "val Loss: 0.16557666 Acc: 0.94488760\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.19686724 Acc: 0.92525613\n",
      "val Loss: 0.19569806 Acc: 0.93110950\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.20884967 Acc: 0.92207389\n",
      "val Loss: 0.18614823 Acc: 0.93799855\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.19558840 Acc: 0.92673083\n",
      "val Loss: 0.17738585 Acc: 0.94307469\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.19035569 Acc: 0.92805029\n",
      "val Loss: 0.19873035 Acc: 0.93183466\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.20090866 Acc: 0.92393667\n",
      "val Loss: 0.17247822 Acc: 0.94597534\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.18875533 Acc: 0.92983545\n",
      "val Loss: 0.17985664 Acc: 0.94162437\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.19307437 Acc: 0.92727414\n",
      "val Loss: 0.17775686 Acc: 0.93981146\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.18424225 Acc: 0.93053400\n",
      "val Loss: 0.18506121 Acc: 0.94307469\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.17902891 Acc: 0.93123254\n",
      "val Loss: 0.18527007 Acc: 0.93944888\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.17922764 Acc: 0.93146538\n",
      "val Loss: 0.18004428 Acc: 0.94597534\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.17502582 Acc: 0.93363862\n",
      "val Loss: 0.20691737 Acc: 0.94053662\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.17418728 Acc: 0.93480286\n",
      "val Loss: 0.19740596 Acc: 0.94017404\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.18219647 Acc: 0.93169823\n",
      "val Loss: 0.22355216 Acc: 0.94271211\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.18176291 Acc: 0.93231916\n",
      "val Loss: 0.19620768 Acc: 0.93546048\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.17722579 Acc: 0.93185346\n",
      "val Loss: 0.23466084 Acc: 0.94307469\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.17374861 Acc: 0.93488047\n",
      "val Loss: 0.19980724 Acc: 0.94416244\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.17545710 Acc: 0.93255200\n",
      "val Loss: 0.19698312 Acc: 0.93255983\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.17102405 Acc: 0.93488047\n",
      "val Loss: 0.20359559 Acc: 0.94307469\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.16521416 Acc: 0.93635517\n",
      "val Loss: 0.19160450 Acc: 0.94379985\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.16200305 Acc: 0.93883887\n",
      "val Loss: 0.20245994 Acc: 0.94307469\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.16749782 Acc: 0.93674325\n",
      "val Loss: 0.23132740 Acc: 0.94488760\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.17218194 Acc: 0.93627755\n",
      "val Loss: 0.18778566 Acc: 0.94670051\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.16836485 Acc: 0.93604471\n",
      "val Loss: 0.18841870 Acc: 0.94670051\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.15924600 Acc: 0.93806271\n",
      "val Loss: 0.19226399 Acc: 0.94887600\n",
      "New best model found!\n",
      "New record ACC: 0.9488759970993473, previous record acc: 0.9485134155184917\n",
      "New record acc is SAVED: 0.9488759970993473\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.16132946 Acc: 0.93883887\n",
      "val Loss: 0.21215921 Acc: 0.95068891\n",
      "New best model found!\n",
      "New record ACC: 0.9506889050036258, previous record acc: 0.9488759970993473\n",
      "New record acc is SAVED: 0.9506889050036258\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.15870737 Acc: 0.94264204\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19/weights_CXR/MixNet_Extra_Large_Dataset_20200630.pth'\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = 200,\n",
    "                                                 checkpoint = None #torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
