{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dEaGqShwJKT"
   },
   "source": [
    "# Trong đại dịch Covid-19 có nguồn gốc từ Wuhan, Trung Quốc đã làm ảnh hưởng tới cuộc sống của nhân loại, cướp đi sinh mạng của ít nhất 200.000 người vô tội và sẽ còn tiếp tục tăng trong thời gian tới.\n",
    "## Để phục vụ công tác chẩn đoán bệnh, các nhà khoa học đã tìm cách áp dụng trí thông minh nhân tạo vào trong việc xử lí và chẩn đoán ảnh CT và X quang chụp phổi để đánh giá tổn thương và phân loại viêm phổi do các nguyên nhân khác nhau, trong đó có Covid-19.\n",
    "## Trong bài này, mình sử dụng dataset tại đây: https://covidresearch.ai/datasets/dataset?id=2. Theo như tìm hiểu về cơ sở dữ liệu này, có lẽ nó được tiếp thu từ 2 nghiên cứu trước đó là bài báo này https://arxiv.org/abs/2003.11597 (địa chỉ github: https://github.com/ieee8023/covid-chestxray-dataset) và bài báo này https://arxiv.org/abs/2003.09871 (https://github.com/lindawangg/COVID-Net).\n",
    "## Gần đây có bài báo công bố sử dụng mạng EfficientNet (bài báo về mạng tại đây https://arxiv.org/pdf/1905.11946.pdf) để chẩn đoán dataset này cho kết quả có độ nhạy và độ đặc hiệu cao hơn hẳn các kết quả trước đó. Các bạn có thể tham khảo bài báo này tại đây: https://arxiv.org/pdf/2004.05717.pdf. Kết quả bài báo chỉ ra rằng họ đã thêm vào mạng EfficientNet_B0 một số lớp để cải thiện khả năng phân loại. Tuy nhiên bài báo sử dụng Framework là Keras, còn trong bài lặp lại thí nghiệm này, mình sử dụng Framework là PyTorch với đóng góp rất lớn của anh Ross Wightman khi xây dựng các mạng thần kinh tích chập sâu cho công việc phân loại ảnh (các bạn có thể tham khảo code tại đây https://github.com/rwightman/pytorch-image-models).\n",
    "### Bên cạnh việc sử dụng Framework khác với bài báo gốc, mình cũng có 1 số thay đổi như mình dùng hàm tối ưu là SGD thay vì ADAM, và mình bổ thêm kĩ thuật Augmentation (ở đây mình dùng thêm kĩ thuật RandAugmentation tại bài báo này https://arxiv.org/abs/1909.13719) để nâng cao độ chính xác.\n",
    "### Mình cũng đã thử huấn luyện dataset này với các mạng khác nhau, tuy nhiên kết quả phân loại có lẽ vẫn hiệu quả nhất với mạng EfficientNet_B0.\n",
    "### Tuy nhiên, để mô hình này có thể sử dụng trong thực tiễn, chắc chắn cần phải tiến hành internal và external validity qua nhiều bước khác nhau. Thêm vào đó, chúng ta hoàn toàn có thể nghĩ đến kĩ thuật ensemble voting để tăng tính chính xác cho công cụ chẩn đoán!\n",
    "# For fun, mình xây dựng thử nền tảng web dùng cho chẩn đoán các ảnh X quang vùng ngực xem bệnh nhân có nhiễm Covid-19 hay không. Các bạn có thể tham khảo tại địa chỉ github của minh [https://github.com/linhduongtuan/Covid-19_Xray_Classifier/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID', 'non-COVID']\n",
      "{'train': 1985, 'test': 497}\n",
      "cuda:0\n",
      "{0: 'COVID', 1: 'non-COVID'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 3, 224, 224])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/linh/Downloads/Covid-19_CT'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/test'\n",
    "\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        ImageNetPolicy(),\n",
    "        Cutout(size=16),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "batch_size = 100\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4, pin_memory = True)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['train'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['test']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 20, cat_to_name)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 20, cat_to_name)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "#model = timm.create_model('resnet50', pretrained=True)\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "model.classifier #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of the model is: 7919262\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "fc = nn.Sequential(OrderedDict([#('fc1', nn.Linear(1280, 1000, bias=True)),\n",
    "                                 ('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, 2)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.fc = fc\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01,momentum=0.9,\n",
    "                      nesterov=True,\n",
    "                      weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "#show our model architechture and send to GPU\n",
    "model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_loss < best_loss:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record loss: {epoch_loss}, previous record loss: {best_loss}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record loss is SAVED: {epoch_loss}')\n",
    "\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded\n",
      "Val loss: 0.060337990691034606, Val accuracy: 0.9798792756539236\n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.14588448 Acc: 0.93803526\n",
      "test Loss: 0.06665734 Acc: 0.97987928\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.14259665 Acc: 0.94105793\n",
      "test Loss: 0.07134537 Acc: 0.97786720\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.16526187 Acc: 0.93602015\n",
      "test Loss: 0.05918342 Acc: 0.97987928\n",
      "New best model found!\n",
      "New record loss: 0.059183418537139654, previous record loss: 0.060337990691034606\n",
      "New record loss is SAVED: 0.059183418537139654\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.15320715 Acc: 0.93047859\n",
      "test Loss: 0.06958803 Acc: 0.97585513\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.14487933 Acc: 0.93602015\n",
      "test Loss: 0.06096729 Acc: 0.97786720\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.14975310 Acc: 0.93450882\n",
      "test Loss: 0.07078880 Acc: 0.97786720\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.14613260 Acc: 0.94206549\n",
      "test Loss: 0.05894058 Acc: 0.97987928\n",
      "New best model found!\n",
      "New record loss: 0.05894057532881107, previous record loss: 0.059183418537139654\n",
      "New record loss is SAVED: 0.05894057532881107\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.14863860 Acc: 0.93753149\n",
      "test Loss: 0.06478667 Acc: 0.97786720\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.14299384 Acc: 0.94256927\n",
      "test Loss: 0.07469582 Acc: 0.97987928\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.15972700 Acc: 0.92896725\n",
      "test Loss: 0.05630720 Acc: 0.97987928\n",
      "New best model found!\n",
      "New record loss: 0.05630719785201897, previous record loss: 0.05894057532881107\n",
      "New record loss is SAVED: 0.05630719785201897\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.15514487 Acc: 0.93602015\n",
      "test Loss: 0.06256130 Acc: 0.97987928\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.15933725 Acc: 0.93148615\n",
      "test Loss: 0.06179561 Acc: 0.97987928\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.15093569 Acc: 0.93602015\n",
      "test Loss: 0.07082571 Acc: 0.97786720\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.13931031 Acc: 0.94105793\n",
      "test Loss: 0.06621831 Acc: 0.97987928\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.13969513 Acc: 0.94408060\n",
      "test Loss: 0.06262657 Acc: 0.97585513\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.14097931 Acc: 0.94458438\n",
      "test Loss: 0.07859207 Acc: 0.97585513\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.16275431 Acc: 0.92695214\n",
      "test Loss: 0.07218272 Acc: 0.97987928\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.16191317 Acc: 0.92544081\n",
      "test Loss: 0.08929072 Acc: 0.97384306\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.15231664 Acc: 0.93602015\n",
      "test Loss: 0.06946309 Acc: 0.97987928\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.13863419 Acc: 0.94458438\n",
      "test Loss: 0.06102781 Acc: 0.97987928\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.13529021 Acc: 0.94760705\n",
      "test Loss: 0.06964154 Acc: 0.97786720\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.15107545 Acc: 0.93702771\n",
      "test Loss: 0.07070326 Acc: 0.97786720\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.14908134 Acc: 0.93652393\n",
      "test Loss: 0.06253359 Acc: 0.97987928\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.15723934 Acc: 0.92947103\n",
      "test Loss: 0.06011472 Acc: 0.97987928\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.14301182 Acc: 0.93853904\n",
      "test Loss: 0.07191038 Acc: 0.97585513\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.14105919 Acc: 0.93803526\n",
      "test Loss: 0.07104900 Acc: 0.97786720\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.16164382 Acc: 0.93400504\n",
      "test Loss: 0.06547806 Acc: 0.97786720\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.17403862 Acc: 0.92644836\n",
      "test Loss: 0.07648899 Acc: 0.97585513\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.14374867 Acc: 0.94307305\n",
      "test Loss: 0.08070787 Acc: 0.97384306\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.13895716 Acc: 0.94458438\n",
      "test Loss: 0.06097808 Acc: 0.97987928\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.15199275 Acc: 0.93299748\n",
      "test Loss: 0.05817175 Acc: 0.97786720\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.15938183 Acc: 0.93148615\n",
      "test Loss: 0.07521933 Acc: 0.97384306\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.15079932 Acc: 0.93551637\n",
      "test Loss: 0.06353942 Acc: 0.97786720\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.14635308 Acc: 0.93702771\n",
      "test Loss: 0.06509582 Acc: 0.97786720\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.14295582 Acc: 0.93904282\n",
      "test Loss: 0.07287107 Acc: 0.97585513\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.15000161 Acc: 0.94206549\n",
      "test Loss: 0.08023094 Acc: 0.97786720\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.16267500 Acc: 0.93098237\n",
      "test Loss: 0.06573645 Acc: 0.97786720\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.15662373 Acc: 0.92947103\n",
      "test Loss: 0.05797619 Acc: 0.97987928\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.16082488 Acc: 0.93098237\n",
      "test Loss: 0.07212335 Acc: 0.97786720\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.16025189 Acc: 0.92947103\n",
      "test Loss: 0.06695181 Acc: 0.97987928\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.14992796 Acc: 0.94156171\n",
      "test Loss: 0.06062972 Acc: 0.97987928\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.15704046 Acc: 0.93350126\n",
      "test Loss: 0.07064045 Acc: 0.97987928\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.14024220 Acc: 0.94861461\n",
      "test Loss: 0.06475165 Acc: 0.98189135\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.13743524 Acc: 0.93803526\n",
      "test Loss: 0.07366138 Acc: 0.97585513\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.15077609 Acc: 0.93551637\n",
      "test Loss: 0.06747944 Acc: 0.97987928\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.13799928 Acc: 0.94206549\n",
      "test Loss: 0.07206902 Acc: 0.97786720\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.13144907 Acc: 0.94005038\n",
      "test Loss: 0.07578685 Acc: 0.97786720\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.14884757 Acc: 0.93954660\n",
      "test Loss: 0.05690539 Acc: 0.97987928\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.15774892 Acc: 0.93450882\n",
      "test Loss: 0.06138893 Acc: 0.97987928\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.14435291 Acc: 0.93954660\n",
      "test Loss: 0.06282284 Acc: 0.97987928\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.16053194 Acc: 0.92997481\n",
      "test Loss: 0.07040599 Acc: 0.97786720\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.15799930 Acc: 0.92947103\n",
      "test Loss: 0.07160936 Acc: 0.97585513\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.14576008 Acc: 0.93904282\n",
      "test Loss: 0.07091187 Acc: 0.97987928\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.14880212 Acc: 0.93803526\n",
      "test Loss: 0.06383187 Acc: 0.97786720\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.16258022 Acc: 0.93148615\n",
      "test Loss: 0.06792294 Acc: 0.97786720\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.14438951 Acc: 0.94357683\n",
      "test Loss: 0.06193103 Acc: 0.97987928\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.13476533 Acc: 0.94861461\n",
      "test Loss: 0.06410428 Acc: 0.97987928\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.14782894 Acc: 0.93753149\n",
      "test Loss: 0.06371131 Acc: 0.97987928\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.15099456 Acc: 0.93400504\n",
      "test Loss: 0.06824278 Acc: 0.97786720\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.14935272 Acc: 0.94307305\n",
      "test Loss: 0.08721911 Acc: 0.97585513\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.16129596 Acc: 0.93501259\n",
      "test Loss: 0.06029178 Acc: 0.97987928\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.15608598 Acc: 0.93450882\n",
      "test Loss: 0.06239772 Acc: 0.97786720\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.14526995 Acc: 0.93904282\n",
      "test Loss: 0.06646271 Acc: 0.97786720\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.14005379 Acc: 0.94005038\n",
      "test Loss: 0.06531159 Acc: 0.97786720\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.15482197 Acc: 0.93652393\n",
      "test Loss: 0.05742596 Acc: 0.97987928\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.14235662 Acc: 0.94458438\n",
      "test Loss: 0.06650447 Acc: 0.97786720\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.16764785 Acc: 0.93551637\n",
      "test Loss: 0.05988553 Acc: 0.97786720\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.14231166 Acc: 0.93400504\n",
      "test Loss: 0.06520257 Acc: 0.97987928\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.13791303 Acc: 0.94659950\n",
      "test Loss: 0.06833391 Acc: 0.97987928\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.17315367 Acc: 0.92241814\n",
      "test Loss: 0.06853644 Acc: 0.97987928\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.13036745 Acc: 0.94559194\n",
      "test Loss: 0.07438995 Acc: 0.97786720\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.14167433 Acc: 0.94609572\n",
      "test Loss: 0.06988309 Acc: 0.97987928\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.14338013 Acc: 0.94005038\n",
      "test Loss: 0.07393323 Acc: 0.97987928\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.14740021 Acc: 0.93853904\n",
      "test Loss: 0.07085796 Acc: 0.97987928\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.13460379 Acc: 0.94256927\n",
      "test Loss: 0.06960422 Acc: 0.97786720\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.14184453 Acc: 0.93652393\n",
      "test Loss: 0.06281116 Acc: 0.97987928\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.14692028 Acc: 0.94105793\n",
      "test Loss: 0.06727772 Acc: 0.97786720\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.14912804 Acc: 0.93652393\n",
      "test Loss: 0.06262083 Acc: 0.97786720\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.15375136 Acc: 0.93450882\n",
      "test Loss: 0.07176619 Acc: 0.98189135\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.15190829 Acc: 0.93954660\n",
      "test Loss: 0.07831557 Acc: 0.97585513\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.16116547 Acc: 0.93299748\n",
      "test Loss: 0.06148065 Acc: 0.97786720\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.14289535 Acc: 0.94156171\n",
      "test Loss: 0.05896530 Acc: 0.97786720\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.15494953 Acc: 0.93551637\n",
      "test Loss: 0.06924463 Acc: 0.97786720\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.14306584 Acc: 0.93904282\n",
      "test Loss: 0.06271275 Acc: 0.97987928\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.14041329 Acc: 0.94609572\n",
      "test Loss: 0.07495177 Acc: 0.97786720\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.16317134 Acc: 0.93299748\n",
      "test Loss: 0.06140291 Acc: 0.97786720\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.14922373 Acc: 0.93652393\n",
      "test Loss: 0.07485021 Acc: 0.97786720\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.14917202 Acc: 0.93551637\n",
      "test Loss: 0.06080889 Acc: 0.97786720\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.14306471 Acc: 0.93652393\n",
      "test Loss: 0.06760594 Acc: 0.97987928\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.14029106 Acc: 0.94256927\n",
      "test Loss: 0.07242719 Acc: 0.97786720\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.15549644 Acc: 0.93148615\n",
      "test Loss: 0.06490088 Acc: 0.97585513\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.15425791 Acc: 0.92896725\n",
      "test Loss: 0.06228571 Acc: 0.97987928\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.13531845 Acc: 0.95113350\n",
      "test Loss: 0.06651398 Acc: 0.97987928\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.15125697 Acc: 0.93853904\n",
      "test Loss: 0.06495484 Acc: 0.97786720\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.16782138 Acc: 0.92342569\n",
      "test Loss: 0.07052081 Acc: 0.97786720\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.15163015 Acc: 0.93803526\n",
      "test Loss: 0.07033532 Acc: 0.97786720\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.14371616 Acc: 0.94005038\n",
      "test Loss: 0.08587729 Acc: 0.97585513\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.14981511 Acc: 0.93904282\n",
      "test Loss: 0.07017877 Acc: 0.97987928\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.14801990 Acc: 0.93853904\n",
      "test Loss: 0.06803223 Acc: 0.97786720\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.16673943 Acc: 0.92695214\n",
      "test Loss: 0.07278225 Acc: 0.97987928\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.15249998 Acc: 0.93602015\n",
      "test Loss: 0.07421113 Acc: 0.97585513\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.14145674 Acc: 0.93904282\n",
      "test Loss: 0.06555356 Acc: 0.97987928\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.15913828 Acc: 0.93551637\n",
      "test Loss: 0.06666246 Acc: 0.97987928\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.15079606 Acc: 0.93198992\n",
      "test Loss: 0.07141025 Acc: 0.97786720\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.16420754 Acc: 0.92997481\n",
      "test Loss: 0.07223265 Acc: 0.97987928\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.14108480 Acc: 0.93904282\n",
      "test Loss: 0.06568542 Acc: 0.97987928\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.14832274 Acc: 0.93904282\n",
      "test Loss: 0.05851789 Acc: 0.97786720\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.15172559 Acc: 0.94005038\n",
      "test Loss: 0.06335559 Acc: 0.97987928\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.15267156 Acc: 0.94005038\n",
      "test Loss: 0.07927924 Acc: 0.97786720\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.14525349 Acc: 0.93702771\n",
      "test Loss: 0.06168599 Acc: 0.97987928\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.13547062 Acc: 0.94508816\n",
      "test Loss: 0.06562631 Acc: 0.97987928\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.15690064 Acc: 0.93350126\n",
      "test Loss: 0.07060684 Acc: 0.97786720\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.13626594 Acc: 0.94408060\n",
      "test Loss: 0.05979386 Acc: 0.97987928\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.14986965 Acc: 0.93450882\n",
      "test Loss: 0.06035457 Acc: 0.97987928\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.16000863 Acc: 0.93047859\n",
      "test Loss: 0.07089602 Acc: 0.97786720\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.15423366 Acc: 0.93501259\n",
      "test Loss: 0.05895598 Acc: 0.97987928\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.17135432 Acc: 0.92695214\n",
      "test Loss: 0.06390262 Acc: 0.97987928\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.14641634 Acc: 0.94256927\n",
      "test Loss: 0.06815004 Acc: 0.97987928\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.14811844 Acc: 0.93400504\n",
      "test Loss: 0.07151131 Acc: 0.97786720\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.13231670 Acc: 0.94307305\n",
      "test Loss: 0.06933567 Acc: 0.97987928\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.15072136 Acc: 0.93350126\n",
      "test Loss: 0.05785603 Acc: 0.97987928\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.15481028 Acc: 0.93904282\n",
      "test Loss: 0.06834538 Acc: 0.97987928\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.15301880 Acc: 0.93098237\n",
      "test Loss: 0.06892047 Acc: 0.97786720\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.14294946 Acc: 0.94357683\n",
      "test Loss: 0.06262193 Acc: 0.97987928\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.14811456 Acc: 0.93299748\n",
      "test Loss: 0.06388214 Acc: 0.97987928\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.13861349 Acc: 0.93450882\n",
      "test Loss: 0.05518071 Acc: 0.97987928\n",
      "New best model found!\n",
      "New record loss: 0.05518070503533396, previous record loss: 0.05630719785201897\n",
      "New record loss is SAVED: 0.05518070503533396\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.15416366 Acc: 0.93249370\n",
      "test Loss: 0.06359083 Acc: 0.97786720\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.14256373 Acc: 0.94256927\n",
      "test Loss: 0.07188702 Acc: 0.97786720\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.15906240 Acc: 0.93299748\n",
      "test Loss: 0.05948695 Acc: 0.97987928\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.14912987 Acc: 0.93602015\n",
      "test Loss: 0.06419398 Acc: 0.97786720\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.16741457 Acc: 0.92947103\n",
      "test Loss: 0.07339543 Acc: 0.97987928\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.15112123 Acc: 0.93702771\n",
      "test Loss: 0.07020843 Acc: 0.97585513\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.14138221 Acc: 0.93853904\n",
      "test Loss: 0.07106975 Acc: 0.97786720\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.14575386 Acc: 0.93249370\n",
      "test Loss: 0.05767658 Acc: 0.97987928\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.15833082 Acc: 0.93299748\n",
      "test Loss: 0.06972806 Acc: 0.97786720\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.13227017 Acc: 0.94357683\n",
      "test Loss: 0.05382851 Acc: 0.97786720\n",
      "New best model found!\n",
      "New record loss: 0.05382851230531511, previous record loss: 0.05518070503533396\n",
      "New record loss is SAVED: 0.05382851230531511\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.14694317 Acc: 0.93904282\n",
      "test Loss: 0.07149978 Acc: 0.98189135\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.15646967 Acc: 0.93450882\n",
      "test Loss: 0.06995810 Acc: 0.97786720\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.14946451 Acc: 0.93803526\n",
      "test Loss: 0.06425701 Acc: 0.97987928\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.15363105 Acc: 0.93551637\n",
      "test Loss: 0.07269545 Acc: 0.97585513\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.14087530 Acc: 0.94156171\n",
      "test Loss: 0.07179586 Acc: 0.97987928\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.15303586 Acc: 0.94005038\n",
      "test Loss: 0.07063408 Acc: 0.97786720\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.15478492 Acc: 0.93551637\n",
      "test Loss: 0.07131813 Acc: 0.97786720\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.14838810 Acc: 0.93400504\n",
      "test Loss: 0.06793765 Acc: 0.97987928\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.13491578 Acc: 0.94811083\n",
      "test Loss: 0.06328535 Acc: 0.97987928\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.15219475 Acc: 0.93501259\n",
      "test Loss: 0.06922382 Acc: 0.97786720\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.15711861 Acc: 0.92997481\n",
      "test Loss: 0.08256469 Acc: 0.97585513\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.15000469 Acc: 0.94357683\n",
      "test Loss: 0.07554876 Acc: 0.97585513\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.16770983 Acc: 0.93450882\n",
      "test Loss: 0.06840532 Acc: 0.97786720\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.14759514 Acc: 0.94307305\n",
      "test Loss: 0.06355491 Acc: 0.97987928\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.13622673 Acc: 0.94710327\n",
      "test Loss: 0.06224800 Acc: 0.97987928\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.15918938 Acc: 0.92896725\n",
      "test Loss: 0.06908472 Acc: 0.97987928\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.14965619 Acc: 0.93501259\n",
      "test Loss: 0.06834478 Acc: 0.97786720\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.14975058 Acc: 0.93501259\n",
      "test Loss: 0.07447478 Acc: 0.97585513\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.14410439 Acc: 0.93602015\n",
      "test Loss: 0.06161946 Acc: 0.97786720\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.15627491 Acc: 0.93803526\n",
      "test Loss: 0.06660075 Acc: 0.97786720\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.14891923 Acc: 0.94005038\n",
      "test Loss: 0.06375517 Acc: 0.97786720\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.13730321 Acc: 0.94508816\n",
      "test Loss: 0.06952350 Acc: 0.97987928\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.15963777 Acc: 0.93450882\n",
      "test Loss: 0.06433678 Acc: 0.97987928\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.14055776 Acc: 0.94559194\n",
      "test Loss: 0.07855459 Acc: 0.97585513\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.15933916 Acc: 0.93198992\n",
      "test Loss: 0.06004820 Acc: 0.97786720\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.15236159 Acc: 0.93602015\n",
      "test Loss: 0.07202190 Acc: 0.97585513\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.13550861 Acc: 0.94811083\n",
      "test Loss: 0.05872844 Acc: 0.97987928\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.15395404 Acc: 0.93299748\n",
      "test Loss: 0.07169342 Acc: 0.97786720\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.13942535 Acc: 0.93954660\n",
      "test Loss: 0.06517568 Acc: 0.97987928\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.15627574 Acc: 0.93148615\n",
      "test Loss: 0.06740162 Acc: 0.97786720\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.15783080 Acc: 0.93350126\n",
      "test Loss: 0.06758877 Acc: 0.97987928\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.15433096 Acc: 0.93602015\n",
      "test Loss: 0.07049339 Acc: 0.97786720\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.15183000 Acc: 0.93299748\n",
      "test Loss: 0.05983858 Acc: 0.97987928\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.14792140 Acc: 0.93400504\n",
      "test Loss: 0.07524472 Acc: 0.97384306\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.14804285 Acc: 0.92846348\n",
      "test Loss: 0.06460269 Acc: 0.97987928\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.14854450 Acc: 0.93853904\n",
      "test Loss: 0.06806163 Acc: 0.97987928\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.14789389 Acc: 0.94408060\n",
      "test Loss: 0.07310760 Acc: 0.97786720\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.14232527 Acc: 0.94760705\n",
      "test Loss: 0.06743599 Acc: 0.97786720\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.14920687 Acc: 0.93904282\n",
      "test Loss: 0.07057987 Acc: 0.97585513\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.13463968 Acc: 0.94559194\n",
      "test Loss: 0.08006560 Acc: 0.97585513\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.13749501 Acc: 0.94307305\n",
      "test Loss: 0.06101076 Acc: 0.97987928\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.14892666 Acc: 0.93148615\n",
      "test Loss: 0.06762759 Acc: 0.97786720\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.13856649 Acc: 0.94408060\n",
      "test Loss: 0.06733799 Acc: 0.97987928\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.13674445 Acc: 0.94458438\n",
      "test Loss: 0.05758361 Acc: 0.97987928\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.13368455 Acc: 0.94659950\n",
      "test Loss: 0.06648993 Acc: 0.97987928\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.14826536 Acc: 0.93501259\n",
      "test Loss: 0.07351745 Acc: 0.97585513\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.13591423 Acc: 0.94357683\n",
      "test Loss: 0.07552014 Acc: 0.97585513\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.14594957 Acc: 0.93702771\n",
      "test Loss: 0.06364678 Acc: 0.97987928\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.16153680 Acc: 0.93299748\n",
      "test Loss: 0.08129488 Acc: 0.97585513\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.15341413 Acc: 0.93551637\n",
      "test Loss: 0.07977911 Acc: 0.97786720\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.15902250 Acc: 0.92392947\n",
      "test Loss: 0.07851209 Acc: 0.97786720\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.15636334 Acc: 0.93249370\n",
      "test Loss: 0.07619063 Acc: 0.97786720\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.15742664 Acc: 0.92947103\n",
      "test Loss: 0.06408030 Acc: 0.97786720\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.15303128 Acc: 0.93350126\n",
      "test Loss: 0.07521686 Acc: 0.97786720\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.15310748 Acc: 0.93803526\n",
      "test Loss: 0.06480603 Acc: 0.97585513\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.15395981 Acc: 0.93299748\n",
      "test Loss: 0.07528090 Acc: 0.97786720\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "train Loss: 0.14451982 Acc: 0.94206549\n",
      "test Loss: 0.06066841 Acc: 0.97987928\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.15036341 Acc: 0.93753149\n",
      "test Loss: 0.06980585 Acc: 0.97585513\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.14987801 Acc: 0.93702771\n",
      "test Loss: 0.07002495 Acc: 0.97987928\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.16447342 Acc: 0.92493703\n",
      "test Loss: 0.06821683 Acc: 0.97987928\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.14883325 Acc: 0.94307305\n",
      "test Loss: 0.06188300 Acc: 0.97786720\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.15597882 Acc: 0.93753149\n",
      "test Loss: 0.07048185 Acc: 0.97987928\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.14623214 Acc: 0.93954660\n",
      "test Loss: 0.07073992 Acc: 0.97786720\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.14258847 Acc: 0.94256927\n",
      "test Loss: 0.06520701 Acc: 0.97786720\n",
      "\n",
      "Training complete in 46m 8s\n",
      "Best val Acc: 0.97786720 Best val loss: 0.05382851\n"
     ]
    }
   ],
   "source": [
    "CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CT/weights/EfficientNet_B0_Covid-19.pth'\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = 200,\n",
    "                                                 checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
