{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dEaGqShwJKT"
   },
   "source": [
    "# Trong đại dịch Covid-19 có nguồn gốc từ Wuhan, Trung Quốc đã làm ảnh hưởng tới cuộc sống của nhân loại, cướp đi sinh mạng của ít nhất 200.000 người vô tội và sẽ còn tiếp tục tăng trong thời gian tới.\n",
    "## Để phục vụ công tác chẩn đoán bệnh, các nhà khoa học đã tìm cách áp dụng trí thông minh nhân tạo vào trong việc xử lí và chẩn đoán ảnh CT và X quang chụp phổi để đánh giá tổn thương và phân loại viêm phổi do các nguyên nhân khác nhau, trong đó có Covid-19.\n",
    "## Trong bài này, mình sử dụng dataset tại đây: https://covidresearch.ai/datasets/dataset?id=2. Theo như tìm hiểu về cơ sở dữ liệu này, có lẽ nó được tiếp thu từ 2 nghiên cứu trước đó là bài báo này https://arxiv.org/abs/2003.11597 (địa chỉ github: https://github.com/ieee8023/covid-chestxray-dataset) và bài báo này https://arxiv.org/abs/2003.09871 (https://github.com/lindawangg/COVID-Net).\n",
    "## Gần đây có bài báo công bố sử dụng mạng EfficientNet (bài báo về mạng tại đây https://arxiv.org/pdf/1905.11946.pdf) để chẩn đoán dataset này cho kết quả có độ nhạy và độ đặc hiệu cao hơn hẳn các kết quả trước đó. Các bạn có thể tham khảo bài báo này tại đây: https://arxiv.org/pdf/2004.05717.pdf. Kết quả bài báo chỉ ra rằng họ đã thêm vào mạng EfficientNet_B0 một số lớp để cải thiện khả năng phân loại. Tuy nhiên bài báo sử dụng Framework là Keras, còn trong bài lặp lại thí nghiệm này, mình sử dụng Framework là PyTorch với đóng góp rất lớn của anh Ross Wightman khi xây dựng các mạng thần kinh tích chập sâu cho công việc phân loại ảnh (các bạn có thể tham khảo code tại đây https://github.com/rwightman/pytorch-image-models).\n",
    "### Bên cạnh việc sử dụng Framework khác với bài báo gốc, mình cũng có 1 số thay đổi như mình dùng hàm tối ưu là SGD thay vì ADAM, và mình bổ thêm kĩ thuật Augmentation (ở đây mình dùng thêm kĩ thuật RandAugmentation tại bài báo này https://arxiv.org/abs/1909.13719) để nâng cao độ chính xác.\n",
    "### Mình cũng đã thử huấn luyện dataset này với các mạng khác nhau, tuy nhiên kết quả phân loại có lẽ vẫn hiệu quả nhất với mạng EfficientNet_B0.\n",
    "### Tuy nhiên, để mô hình này có thể sử dụng trong thực tiễn, chắc chắn cần phải tiến hành internal và external validity qua nhiều bước khác nhau. Thêm vào đó, chúng ta hoàn toàn có thể nghĩ đến kĩ thuật ensemble voting để tăng tính chính xác cho công cụ chẩn đoán!\n",
    "# For fun, mình xây dựng thử nền tảng web dùng cho chẩn đoán các ảnh X quang vùng ngực xem bệnh nhân có nhiễm Covid-19 hay không. Các bạn có thể tham khảo tại địa chỉ github của minh [https://github.com/linhduongtuan/Covid-19_Xray_Classifier/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID', 'non-COVID']\n",
      "{'train': 1985, 'test': 497}\n",
      "cuda:0\n",
      "{0: 'COVID', 1: 'non-COVID'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 3, 224, 224])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/linh/Downloads/Covid-19_CT'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/test'\n",
    "\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        ImageNetPolicy(),\n",
    "        Cutout(size=16),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "batch_size = 44\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4, pin_memory = True)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['train'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['test']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 20, cat_to_name)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 20, cat_to_name)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1536, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "#model = timm.create_model('resnet50', pretrained=True)\n",
    "model = timm.create_model('mixnet_xl', pretrained=True)\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "model.classifier #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of the model is: 14015482\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "fc = nn.Sequential(OrderedDict([('fc1', nn.Linear(1536, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, 2)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.fc = fc\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01,momentum=0.9,\n",
    "                      nesterov=True,\n",
    "                      weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "#show our model architechture and send to GPU\n",
    "model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_loss < best_loss:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record loss: {epoch_loss}, previous record loss: {best_loss}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record loss is SAVED: {epoch_loss}')\n",
    "\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded\n",
      "Val loss: 0.02006731217196257, Val accuracy: 0.9919517102615695\n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.10405291 Acc: 0.95465995\n",
      "test Loss: 0.02198312 Acc: 0.99195171\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.11100209 Acc: 0.95516373\n",
      "test Loss: 0.02469608 Acc: 0.99195171\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.10546896 Acc: 0.95617128\n",
      "test Loss: 0.02382426 Acc: 0.98591549\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.09845995 Acc: 0.96322418\n",
      "test Loss: 0.02107511 Acc: 0.98993964\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.10399646 Acc: 0.95919395\n",
      "test Loss: 0.02335610 Acc: 0.98993964\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.11653365 Acc: 0.94811083\n",
      "test Loss: 0.02213998 Acc: 0.98993964\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.10562727 Acc: 0.95163728\n",
      "test Loss: 0.01988330 Acc: 0.99195171\n",
      "New best model found!\n",
      "New record loss: 0.0198832995078415, previous record loss: 0.02006731217196257\n",
      "New record loss is SAVED: 0.0198832995078415\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.11050649 Acc: 0.95264484\n",
      "test Loss: 0.02124389 Acc: 0.98993964\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.10761441 Acc: 0.95667506\n",
      "test Loss: 0.02155890 Acc: 0.99195171\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.10086006 Acc: 0.95465995\n",
      "test Loss: 0.02298375 Acc: 0.99195171\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.11174608 Acc: 0.95214106\n",
      "test Loss: 0.02033860 Acc: 0.98993964\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.10149239 Acc: 0.96221662\n",
      "test Loss: 0.02060928 Acc: 0.98993964\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.09003254 Acc: 0.96624685\n",
      "test Loss: 0.01720872 Acc: 0.99195171\n",
      "New best model found!\n",
      "New record loss: 0.017208719184709773, previous record loss: 0.0198832995078415\n",
      "New record loss is SAVED: 0.017208719184709773\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.09423612 Acc: 0.96272040\n",
      "test Loss: 0.02524989 Acc: 0.98792757\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.10510285 Acc: 0.96221662\n",
      "test Loss: 0.02289429 Acc: 0.98792757\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.09743360 Acc: 0.96171285\n",
      "test Loss: 0.02206041 Acc: 0.99195171\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.11623524 Acc: 0.94861461\n",
      "test Loss: 0.03187238 Acc: 0.98792757\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.10179897 Acc: 0.95869018\n",
      "test Loss: 0.02275402 Acc: 0.99195171\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.11854289 Acc: 0.95465995\n",
      "test Loss: 0.02063686 Acc: 0.99195171\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.10753710 Acc: 0.95768262\n",
      "test Loss: 0.02242557 Acc: 0.98993964\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.11975220 Acc: 0.94861461\n",
      "test Loss: 0.01998646 Acc: 0.99195171\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.10800686 Acc: 0.95566751\n",
      "test Loss: 0.02165393 Acc: 0.98993964\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.11353815 Acc: 0.95264484\n",
      "test Loss: 0.01899418 Acc: 0.99195171\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.12707937 Acc: 0.94710327\n",
      "test Loss: 0.02765470 Acc: 0.98993964\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.10254571 Acc: 0.95667506\n",
      "test Loss: 0.02287325 Acc: 0.99195171\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.10436619 Acc: 0.95617128\n",
      "test Loss: 0.02431940 Acc: 0.98792757\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.10713744 Acc: 0.95717884\n",
      "test Loss: 0.01983253 Acc: 0.98993964\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.11061711 Acc: 0.95062972\n",
      "test Loss: 0.02400514 Acc: 0.98792757\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.09233702 Acc: 0.96523929\n",
      "test Loss: 0.02137267 Acc: 0.98792757\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.10204919 Acc: 0.95465995\n",
      "test Loss: 0.02849836 Acc: 0.98993964\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.09260984 Acc: 0.96775819\n",
      "test Loss: 0.02056849 Acc: 0.98993964\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.11189198 Acc: 0.95365239\n",
      "test Loss: 0.02314659 Acc: 0.98993964\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.10953126 Acc: 0.95365239\n",
      "test Loss: 0.01956071 Acc: 0.99396378\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.10540117 Acc: 0.95717884\n",
      "test Loss: 0.02288393 Acc: 0.99195171\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.11498363 Acc: 0.95113350\n",
      "test Loss: 0.02422229 Acc: 0.98993964\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.10145259 Acc: 0.95314861\n",
      "test Loss: 0.02223234 Acc: 0.98993964\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.11475060 Acc: 0.94962217\n",
      "test Loss: 0.02115169 Acc: 0.99195171\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.11893567 Acc: 0.95113350\n",
      "test Loss: 0.01947177 Acc: 0.98993964\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.09613707 Acc: 0.96221662\n",
      "test Loss: 0.02796512 Acc: 0.98792757\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.12281862 Acc: 0.94659950\n",
      "test Loss: 0.02493227 Acc: 0.98792757\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.10588631 Acc: 0.95516373\n",
      "test Loss: 0.02564423 Acc: 0.99195171\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.10534123 Acc: 0.95465995\n",
      "test Loss: 0.01990864 Acc: 0.99195171\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.10782504 Acc: 0.95516373\n",
      "test Loss: 0.02069591 Acc: 0.98993964\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.10097981 Acc: 0.95667506\n",
      "test Loss: 0.02414441 Acc: 0.98993964\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.12075723 Acc: 0.95214106\n",
      "test Loss: 0.02623832 Acc: 0.98993964\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.10813665 Acc: 0.94962217\n",
      "test Loss: 0.02247168 Acc: 0.98993964\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.10454977 Acc: 0.95717884\n",
      "test Loss: 0.02636399 Acc: 0.98993964\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.11671698 Acc: 0.95062972\n",
      "test Loss: 0.02029435 Acc: 0.98993964\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.09546597 Acc: 0.95969773\n",
      "test Loss: 0.02343589 Acc: 0.98993964\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.11111000 Acc: 0.95415617\n",
      "test Loss: 0.02297251 Acc: 0.99195171\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.10317565 Acc: 0.95617128\n",
      "test Loss: 0.03822059 Acc: 0.98792757\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.12381032 Acc: 0.95012594\n",
      "test Loss: 0.02474533 Acc: 0.98993964\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.11159391 Acc: 0.95465995\n",
      "test Loss: 0.02411200 Acc: 0.99195171\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.12385184 Acc: 0.95163728\n",
      "test Loss: 0.02522910 Acc: 0.98993964\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.10843230 Acc: 0.95818640\n",
      "test Loss: 0.02361365 Acc: 0.98792757\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.10825462 Acc: 0.95163728\n",
      "test Loss: 0.02392142 Acc: 0.99195171\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.10472372 Acc: 0.95717884\n",
      "test Loss: 0.02203735 Acc: 0.98993964\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.10935806 Acc: 0.95365239\n",
      "test Loss: 0.02338551 Acc: 0.98993964\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.09652040 Acc: 0.96372796\n",
      "test Loss: 0.02299577 Acc: 0.98993964\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.10534133 Acc: 0.95516373\n",
      "test Loss: 0.02192556 Acc: 0.99195171\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.09543915 Acc: 0.96372796\n",
      "test Loss: 0.02345166 Acc: 0.98993964\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.10226279 Acc: 0.95717884\n",
      "test Loss: 0.01909697 Acc: 0.99195171\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.11977380 Acc: 0.95012594\n",
      "test Loss: 0.01865322 Acc: 0.99195171\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.10811626 Acc: 0.95314861\n",
      "test Loss: 0.02351548 Acc: 0.98993964\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.10395899 Acc: 0.95869018\n",
      "test Loss: 0.02254590 Acc: 0.99195171\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.09847856 Acc: 0.96070529\n",
      "test Loss: 0.02285753 Acc: 0.99195171\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.09587162 Acc: 0.96322418\n",
      "test Loss: 0.02271890 Acc: 0.98792757\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.11394891 Acc: 0.95465995\n",
      "test Loss: 0.02447360 Acc: 0.98993964\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.10429254 Acc: 0.95969773\n",
      "test Loss: 0.02494767 Acc: 0.98993964\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.10602769 Acc: 0.95264484\n",
      "test Loss: 0.02194345 Acc: 0.99195171\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.12316801 Acc: 0.94458438\n",
      "test Loss: 0.03739318 Acc: 0.98591549\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.10292318 Acc: 0.95163728\n",
      "test Loss: 0.02156952 Acc: 0.99195171\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.11182279 Acc: 0.95264484\n",
      "test Loss: 0.02098711 Acc: 0.98792757\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.10140751 Acc: 0.95869018\n",
      "test Loss: 0.02894658 Acc: 0.98993964\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.11510525 Acc: 0.94811083\n",
      "test Loss: 0.02093794 Acc: 0.99195171\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.11105807 Acc: 0.95516373\n",
      "test Loss: 0.02281190 Acc: 0.98792757\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.10970146 Acc: 0.95566751\n",
      "test Loss: 0.02704724 Acc: 0.98792757\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.10787628 Acc: 0.95113350\n",
      "test Loss: 0.02516242 Acc: 0.98993964\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.11226809 Acc: 0.95214106\n",
      "test Loss: 0.02133505 Acc: 0.98792757\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.10710459 Acc: 0.95818640\n",
      "test Loss: 0.02444163 Acc: 0.98993964\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.09224785 Acc: 0.95818640\n",
      "test Loss: 0.02390826 Acc: 0.99195171\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.10997402 Acc: 0.95516373\n",
      "test Loss: 0.02440878 Acc: 0.98993964\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.09332002 Acc: 0.96322418\n",
      "test Loss: 0.02746925 Acc: 0.98792757\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.10633730 Acc: 0.95566751\n",
      "test Loss: 0.02547601 Acc: 0.98993964\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.09087558 Acc: 0.96624685\n",
      "test Loss: 0.02428016 Acc: 0.98993964\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.09960150 Acc: 0.96423174\n",
      "test Loss: 0.02627752 Acc: 0.98792757\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.11343746 Acc: 0.95012594\n",
      "test Loss: 0.02196920 Acc: 0.99195171\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.10312262 Acc: 0.95566751\n",
      "test Loss: 0.02173361 Acc: 0.99195171\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.09329579 Acc: 0.96473552\n",
      "test Loss: 0.02126695 Acc: 0.99195171\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.10117765 Acc: 0.95768262\n",
      "test Loss: 0.02664614 Acc: 0.98993964\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.09474372 Acc: 0.96473552\n",
      "test Loss: 0.02241941 Acc: 0.98993964\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.10574872 Acc: 0.95617128\n",
      "test Loss: 0.02033971 Acc: 0.99195171\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.10880404 Acc: 0.95113350\n",
      "test Loss: 0.02414564 Acc: 0.98993964\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.09652918 Acc: 0.96322418\n",
      "test Loss: 0.02183507 Acc: 0.98993964\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.10671868 Acc: 0.95969773\n",
      "test Loss: 0.02084032 Acc: 0.99195171\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.10800636 Acc: 0.95617128\n",
      "test Loss: 0.02332410 Acc: 0.98993964\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.10592184 Acc: 0.95163728\n",
      "test Loss: 0.02189383 Acc: 0.99195171\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.11062398 Acc: 0.95465995\n",
      "test Loss: 0.02158057 Acc: 0.99195171\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.10164674 Acc: 0.96020151\n",
      "test Loss: 0.02343830 Acc: 0.98993964\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.09806194 Acc: 0.96171285\n",
      "test Loss: 0.02188347 Acc: 0.98792757\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.09877783 Acc: 0.95465995\n",
      "test Loss: 0.02576170 Acc: 0.98993964\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.10732484 Acc: 0.95667506\n",
      "test Loss: 0.02330689 Acc: 0.98993964\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.10767446 Acc: 0.95264484\n",
      "test Loss: 0.02467530 Acc: 0.99195171\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.11074738 Acc: 0.95062972\n",
      "test Loss: 0.02778552 Acc: 0.98792757\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.11446162 Acc: 0.95264484\n",
      "test Loss: 0.02935227 Acc: 0.98993964\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.10175419 Acc: 0.95667506\n",
      "test Loss: 0.02551058 Acc: 0.99195171\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.10639784 Acc: 0.95667506\n",
      "test Loss: 0.02308699 Acc: 0.98993964\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.11062694 Acc: 0.95717884\n",
      "test Loss: 0.02485608 Acc: 0.98993964\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.10238785 Acc: 0.95768262\n",
      "test Loss: 0.02786583 Acc: 0.98792757\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.11638160 Acc: 0.95264484\n",
      "test Loss: 0.03267969 Acc: 0.98792757\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.09161203 Acc: 0.96322418\n",
      "test Loss: 0.02480766 Acc: 0.98591549\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.11074573 Acc: 0.95264484\n",
      "test Loss: 0.02544931 Acc: 0.98792757\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.10503552 Acc: 0.95415617\n",
      "test Loss: 0.02101193 Acc: 0.98993964\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.12032433 Acc: 0.95062972\n",
      "test Loss: 0.02041047 Acc: 0.98993964\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.09528754 Acc: 0.96372796\n",
      "test Loss: 0.02160086 Acc: 0.98993964\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.12265575 Acc: 0.95012594\n",
      "test Loss: 0.02361146 Acc: 0.99195171\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.10562930 Acc: 0.95617128\n",
      "test Loss: 0.02120586 Acc: 0.99195171\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.10604030 Acc: 0.95214106\n",
      "test Loss: 0.02117553 Acc: 0.99195171\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.11623363 Acc: 0.95113350\n",
      "test Loss: 0.02260432 Acc: 0.99195171\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.12224920 Acc: 0.95113350\n",
      "test Loss: 0.02602544 Acc: 0.99195171\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.10980315 Acc: 0.95314861\n",
      "test Loss: 0.02341582 Acc: 0.98993964\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.11090604 Acc: 0.95516373\n",
      "test Loss: 0.02351694 Acc: 0.98993964\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.12419493 Acc: 0.95012594\n",
      "test Loss: 0.02571450 Acc: 0.98792757\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.10119583 Acc: 0.95465995\n",
      "test Loss: 0.02362399 Acc: 0.98993964\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.09697815 Acc: 0.95919395\n",
      "test Loss: 0.02604163 Acc: 0.99195171\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.10642880 Acc: 0.95717884\n",
      "test Loss: 0.02690642 Acc: 0.98993964\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.10016687 Acc: 0.96020151\n",
      "test Loss: 0.02979653 Acc: 0.98993964\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.09771926 Acc: 0.96120907\n",
      "test Loss: 0.02622491 Acc: 0.98792757\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.10927446 Acc: 0.95314861\n",
      "test Loss: 0.02218033 Acc: 0.99195171\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.09997447 Acc: 0.95818640\n",
      "test Loss: 0.02359275 Acc: 0.98993964\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.10599674 Acc: 0.95818640\n",
      "test Loss: 0.02297516 Acc: 0.98792757\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.12091134 Acc: 0.94559194\n",
      "test Loss: 0.01957854 Acc: 0.98993964\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.11002024 Acc: 0.95516373\n",
      "test Loss: 0.02458577 Acc: 0.98993964\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.11226888 Acc: 0.95667506\n",
      "test Loss: 0.02301732 Acc: 0.99195171\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.09768212 Acc: 0.96120907\n",
      "test Loss: 0.02617395 Acc: 0.99396378\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.09263173 Acc: 0.96372796\n",
      "test Loss: 0.02166250 Acc: 0.98993964\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.09139148 Acc: 0.96675063\n",
      "test Loss: 0.02149855 Acc: 0.99396378\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.10045968 Acc: 0.96221662\n",
      "test Loss: 0.02059835 Acc: 0.98993964\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.10449102 Acc: 0.95969773\n",
      "test Loss: 0.02460160 Acc: 0.98792757\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.10619075 Acc: 0.95415617\n",
      "test Loss: 0.02167054 Acc: 0.99195171\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.09805189 Acc: 0.96070529\n",
      "test Loss: 0.01829234 Acc: 0.99195171\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.11609594 Acc: 0.95314861\n",
      "test Loss: 0.02101492 Acc: 0.99195171\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.09695852 Acc: 0.96423174\n",
      "test Loss: 0.02824431 Acc: 0.98792757\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.10433637 Acc: 0.95768262\n",
      "test Loss: 0.02350702 Acc: 0.98993964\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.11406457 Acc: 0.94811083\n",
      "test Loss: 0.02105366 Acc: 0.99195171\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.09570982 Acc: 0.96171285\n",
      "test Loss: 0.01896575 Acc: 0.98993964\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.10291547 Acc: 0.95717884\n",
      "test Loss: 0.02267194 Acc: 0.99195171\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.09766707 Acc: 0.96171285\n",
      "test Loss: 0.02099672 Acc: 0.98993964\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.10323567 Acc: 0.95365239\n",
      "test Loss: 0.02208446 Acc: 0.99195171\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.10812163 Acc: 0.95516373\n",
      "test Loss: 0.02607305 Acc: 0.99195171\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.10936926 Acc: 0.95465995\n",
      "test Loss: 0.02916504 Acc: 0.98792757\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.10834034 Acc: 0.95516373\n",
      "test Loss: 0.02267359 Acc: 0.99195171\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.10101529 Acc: 0.95818640\n",
      "test Loss: 0.02316090 Acc: 0.98993964\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.10186246 Acc: 0.95768262\n",
      "test Loss: 0.02368846 Acc: 0.98993964\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.12502760 Acc: 0.94458438\n",
      "test Loss: 0.02128648 Acc: 0.98993964\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.09490084 Acc: 0.95516373\n",
      "test Loss: 0.01924871 Acc: 0.98993964\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.10002825 Acc: 0.95516373\n",
      "test Loss: 0.02356341 Acc: 0.98792757\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.10480780 Acc: 0.95516373\n",
      "test Loss: 0.02185042 Acc: 0.99195171\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.11302393 Acc: 0.95314861\n",
      "test Loss: 0.02252108 Acc: 0.98993964\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.11169655 Acc: 0.95365239\n",
      "test Loss: 0.02216200 Acc: 0.99195171\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.11631513 Acc: 0.95465995\n",
      "test Loss: 0.02184357 Acc: 0.98993964\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.11139323 Acc: 0.95516373\n",
      "test Loss: 0.02653289 Acc: 0.98993964\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.11723888 Acc: 0.94861461\n",
      "test Loss: 0.02500352 Acc: 0.98993964\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.10308608 Acc: 0.95818640\n",
      "test Loss: 0.02604402 Acc: 0.98792757\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.09598309 Acc: 0.95818640\n",
      "test Loss: 0.02156148 Acc: 0.98993964\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CT/weights/MixNet_Extra_Large_Covid-19.pth'\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = 200,\n",
    "                                                 checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
