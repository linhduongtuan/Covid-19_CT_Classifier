{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dEaGqShwJKT"
   },
   "source": [
    "# Trong đại dịch Covid-19 có nguồn gốc từ Wuhan, Trung Quốc đã làm ảnh hưởng tới cuộc sống của nhân loại, cướp đi sinh mạng của ít nhất 200.000 người vô tội và sẽ còn tiếp tục tăng trong thời gian tới.\n",
    "## Để phục vụ công tác chẩn đoán bệnh, các nhà khoa học đã tìm cách áp dụng trí thông minh nhân tạo vào trong việc xử lí và chẩn đoán ảnh CT và X quang chụp phổi để đánh giá tổn thương và phân loại viêm phổi do các nguyên nhân khác nhau, trong đó có Covid-19.\n",
    "## Trong bài này, mình sử dụng dataset tại đây: https://covidresearch.ai/datasets/dataset?id=2. Theo như tìm hiểu về cơ sở dữ liệu này, có lẽ nó được tiếp thu từ 2 nghiên cứu trước đó là bài báo này https://arxiv.org/abs/2003.11597 (địa chỉ github: https://github.com/ieee8023/covid-chestxray-dataset) và bài báo này https://arxiv.org/abs/2003.09871 (https://github.com/lindawangg/COVID-Net).\n",
    "## Gần đây có bài báo công bố sử dụng mạng EfficientNet (bài báo về mạng tại đây https://arxiv.org/pdf/1905.11946.pdf) để chẩn đoán dataset này cho kết quả có độ nhạy và độ đặc hiệu cao hơn hẳn các kết quả trước đó. Các bạn có thể tham khảo bài báo này tại đây: https://arxiv.org/pdf/2004.05717.pdf. Kết quả bài báo chỉ ra rằng họ đã thêm vào mạng EfficientNet_B0 một số lớp để cải thiện khả năng phân loại. Tuy nhiên bài báo sử dụng Framework là Keras, còn trong bài lặp lại thí nghiệm này, mình sử dụng Framework là PyTorch với đóng góp rất lớn của anh Ross Wightman khi xây dựng các mạng thần kinh tích chập sâu cho công việc phân loại ảnh (các bạn có thể tham khảo code tại đây https://github.com/rwightman/pytorch-image-models).\n",
    "### Bên cạnh việc sử dụng Framework khác với bài báo gốc, mình cũng có 1 số thay đổi như mình dùng hàm tối ưu là SGD thay vì ADAM, và mình bổ thêm kĩ thuật Augmentation (ở đây mình dùng thêm kĩ thuật RandAugmentation tại bài báo này https://arxiv.org/abs/1909.13719) để nâng cao độ chính xác.\n",
    "### Mình cũng đã thử huấn luyện dataset này với các mạng khác nhau, tuy nhiên kết quả phân loại có lẽ vẫn hiệu quả nhất với mạng EfficientNet_B0.\n",
    "### Tuy nhiên, để mô hình này có thể sử dụng trong thực tiễn, chắc chắn cần phải tiến hành internal và external validity qua nhiều bước khác nhau. Thêm vào đó, chúng ta hoàn toàn có thể nghĩ đến kĩ thuật ensemble voting để tăng tính chính xác cho công cụ chẩn đoán!\n",
    "# For fun, mình xây dựng thử nền tảng web dùng cho chẩn đoán các ảnh X quang vùng ngực xem bệnh nhân có nhiễm Covid-19 hay không. Các bạn có thể tham khảo tại địa chỉ github của minh [https://github.com/linhduongtuan/Covid-19_Xray_Classifier/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID', 'non-COVID']\n",
      "{'train': 1985, 'test': 497}\n",
      "cuda:0\n",
      "{0: 'COVID', 1: 'non-COVID'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 3, 224, 224])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/linh/Downloads/Covid-19_CT'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/test'\n",
    "\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        ImageNetPolicy(),\n",
    "        Cutout(size=16),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "batch_size = 160\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4, pin_memory = True)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['train'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['test']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 20, cat_to_name)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 20, cat_to_name)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "#model = timm.create_model('resnet50', pretrained=True)\n",
    "model = timm.create_model('tresnet_m', pretrained=True)\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "model.head #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34019746\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, 2)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.fc = classifier\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01,momentum=0.9,\n",
    "                      nesterov=True,\n",
    "                      weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "#show our model architechture and send to GPU\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_loss < best_loss:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record loss: {epoch_loss}, previous record loss: {best_loss}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record loss is SAVED: {epoch_loss}')\n",
    "\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded\n",
      "Val loss: 0.03879961209424155, Val accuracy: 0.9899396378269618\n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.09362237 Acc: 0.96070529\n",
      "test Loss: 0.04082891 Acc: 0.98792757\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.09417780 Acc: 0.96171285\n",
      "test Loss: 0.04003910 Acc: 0.98792757\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.10001139 Acc: 0.95869018\n",
      "test Loss: 0.04128009 Acc: 0.98591549\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.08810518 Acc: 0.96574307\n",
      "test Loss: 0.04024153 Acc: 0.98792757\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.09343176 Acc: 0.96322418\n",
      "test Loss: 0.04076977 Acc: 0.98792757\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.09469536 Acc: 0.96171285\n",
      "test Loss: 0.04004014 Acc: 0.98792757\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.08825671 Acc: 0.96372796\n",
      "test Loss: 0.04047035 Acc: 0.98792757\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.09780465 Acc: 0.96020151\n",
      "test Loss: 0.03890772 Acc: 0.98993964\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.09003461 Acc: 0.96423174\n",
      "test Loss: 0.03990328 Acc: 0.98792757\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.09444915 Acc: 0.96221662\n",
      "test Loss: 0.03882905 Acc: 0.98993964\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.09969577 Acc: 0.95163728\n",
      "test Loss: 0.04185507 Acc: 0.98390342\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.10377937 Acc: 0.95969773\n",
      "test Loss: 0.04147930 Acc: 0.98390342\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.09374156 Acc: 0.96322418\n",
      "test Loss: 0.04115585 Acc: 0.98792757\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.08886612 Acc: 0.96120907\n",
      "test Loss: 0.03994925 Acc: 0.98993964\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.08256996 Acc: 0.96675063\n",
      "test Loss: 0.03910272 Acc: 0.98993964\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.09262022 Acc: 0.96322418\n",
      "test Loss: 0.03939181 Acc: 0.98993964\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.09787664 Acc: 0.95214106\n",
      "test Loss: 0.03996484 Acc: 0.98792757\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.09909757 Acc: 0.95869018\n",
      "test Loss: 0.04028433 Acc: 0.98792757\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.09697470 Acc: 0.96120907\n",
      "test Loss: 0.04096046 Acc: 0.98993964\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.09039991 Acc: 0.96120907\n",
      "test Loss: 0.03836936 Acc: 0.98993964\n",
      "New best model found!\n",
      "New record loss: 0.03836935614301285, previous record loss: 0.03879961209424155\n",
      "New record loss is SAVED: 0.03836935614301285\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.09132750 Acc: 0.96221662\n",
      "test Loss: 0.03950969 Acc: 0.98792757\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.08933713 Acc: 0.96120907\n",
      "test Loss: 0.04035224 Acc: 0.98993964\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.09589314 Acc: 0.96272040\n",
      "test Loss: 0.04111014 Acc: 0.98792757\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.08675974 Acc: 0.96523929\n",
      "test Loss: 0.04269709 Acc: 0.98792757\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.09320799 Acc: 0.96221662\n",
      "test Loss: 0.04363073 Acc: 0.98591549\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.08856287 Acc: 0.96221662\n",
      "test Loss: 0.04481424 Acc: 0.98591549\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.10989076 Acc: 0.95012594\n",
      "test Loss: 0.04017731 Acc: 0.98993964\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.09171544 Acc: 0.96372796\n",
      "test Loss: 0.04007940 Acc: 0.98993964\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.09840174 Acc: 0.96020151\n",
      "test Loss: 0.04074324 Acc: 0.98792757\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.09718830 Acc: 0.96070529\n",
      "test Loss: 0.03937940 Acc: 0.98993964\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.08888472 Acc: 0.96423174\n",
      "test Loss: 0.03945935 Acc: 0.98993964\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.08663469 Acc: 0.96020151\n",
      "test Loss: 0.04061284 Acc: 0.98993964\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.10088772 Acc: 0.95919395\n",
      "test Loss: 0.04113953 Acc: 0.98792757\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.09984292 Acc: 0.95919395\n",
      "test Loss: 0.04290189 Acc: 0.98792757\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.09541178 Acc: 0.95667506\n",
      "test Loss: 0.04239002 Acc: 0.98591549\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.10411780 Acc: 0.95617128\n",
      "test Loss: 0.04289797 Acc: 0.98591549\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.09896386 Acc: 0.95869018\n",
      "test Loss: 0.03891716 Acc: 0.98993964\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.10286086 Acc: 0.95516373\n",
      "test Loss: 0.04204788 Acc: 0.98792757\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.08764529 Acc: 0.95919395\n",
      "test Loss: 0.04394109 Acc: 0.98591549\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.10315729 Acc: 0.95717884\n",
      "test Loss: 0.04257714 Acc: 0.98591549\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.08737687 Acc: 0.96070529\n",
      "test Loss: 0.04251778 Acc: 0.98792757\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.09076501 Acc: 0.96221662\n",
      "test Loss: 0.04226944 Acc: 0.98792757\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.09814147 Acc: 0.95717884\n",
      "test Loss: 0.04255032 Acc: 0.98792757\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.09601539 Acc: 0.96423174\n",
      "test Loss: 0.04077961 Acc: 0.98591549\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.09028699 Acc: 0.96473552\n",
      "test Loss: 0.04273072 Acc: 0.98591549\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.09778965 Acc: 0.96120907\n",
      "test Loss: 0.04222276 Acc: 0.98792757\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.08401619 Acc: 0.96372796\n",
      "test Loss: 0.04246743 Acc: 0.98792757\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.10390165 Acc: 0.95919395\n",
      "test Loss: 0.04318248 Acc: 0.98591549\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.10199014 Acc: 0.95566751\n",
      "test Loss: 0.04341549 Acc: 0.98591549\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.09218999 Acc: 0.96120907\n",
      "test Loss: 0.03900234 Acc: 0.98993964\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.10922728 Acc: 0.95465995\n",
      "test Loss: 0.03976930 Acc: 0.98792757\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.09336764 Acc: 0.95919395\n",
      "test Loss: 0.04173788 Acc: 0.98792757\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.07805565 Acc: 0.96826196\n",
      "test Loss: 0.04173078 Acc: 0.98792757\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.10148450 Acc: 0.95768262\n",
      "test Loss: 0.04136134 Acc: 0.98792757\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.09862745 Acc: 0.95768262\n",
      "test Loss: 0.04009299 Acc: 0.98792757\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.08328097 Acc: 0.96523929\n",
      "test Loss: 0.04105796 Acc: 0.98792757\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.09184024 Acc: 0.96322418\n",
      "test Loss: 0.03911455 Acc: 0.98993964\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.09757754 Acc: 0.95818640\n",
      "test Loss: 0.04059436 Acc: 0.98993964\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.09514816 Acc: 0.95969773\n",
      "test Loss: 0.03822065 Acc: 0.98993964\n",
      "New best model found!\n",
      "New record loss: 0.03822064930451303, previous record loss: 0.03836935614301285\n",
      "New record loss is SAVED: 0.03822064930451303\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.10329176 Acc: 0.95768262\n",
      "test Loss: 0.03976827 Acc: 0.98993964\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.09598982 Acc: 0.95365239\n",
      "test Loss: 0.04168118 Acc: 0.98993964\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.10519753 Acc: 0.95163728\n",
      "test Loss: 0.04110176 Acc: 0.98993964\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.09995852 Acc: 0.95717884\n",
      "test Loss: 0.04003868 Acc: 0.98792757\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.08895475 Acc: 0.96272040\n",
      "test Loss: 0.04069098 Acc: 0.98792757\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.09099236 Acc: 0.96473552\n",
      "test Loss: 0.04096820 Acc: 0.98792757\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.08277844 Acc: 0.96221662\n",
      "test Loss: 0.04225610 Acc: 0.98792757\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.09675466 Acc: 0.96272040\n",
      "test Loss: 0.04177786 Acc: 0.98993964\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.09285912 Acc: 0.96322418\n",
      "test Loss: 0.04412930 Acc: 0.98591549\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.09662614 Acc: 0.96020151\n",
      "test Loss: 0.03887853 Acc: 0.98993964\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.10684803 Acc: 0.95617128\n",
      "test Loss: 0.04091555 Acc: 0.98993964\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.09840972 Acc: 0.95566751\n",
      "test Loss: 0.04112051 Acc: 0.98792757\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.09333610 Acc: 0.95818640\n",
      "test Loss: 0.04117699 Acc: 0.98792757\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.09857192 Acc: 0.95919395\n",
      "test Loss: 0.04237652 Acc: 0.98591549\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.08708571 Acc: 0.96624685\n",
      "test Loss: 0.03911080 Acc: 0.98993964\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.09824061 Acc: 0.95768262\n",
      "test Loss: 0.03997743 Acc: 0.98792757\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.09973195 Acc: 0.95919395\n",
      "test Loss: 0.03886999 Acc: 0.98993964\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.08629813 Acc: 0.96624685\n",
      "test Loss: 0.04166822 Acc: 0.98792757\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.09029067 Acc: 0.96020151\n",
      "test Loss: 0.04329121 Acc: 0.98792757\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.08124085 Acc: 0.96675063\n",
      "test Loss: 0.04053576 Acc: 0.98792757\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.09671159 Acc: 0.96423174\n",
      "test Loss: 0.04112395 Acc: 0.98792757\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.09919752 Acc: 0.95314861\n",
      "test Loss: 0.03826062 Acc: 0.98993964\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.08944420 Acc: 0.96272040\n",
      "test Loss: 0.03922657 Acc: 0.98993964\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.08956993 Acc: 0.96523929\n",
      "test Loss: 0.03954011 Acc: 0.98792757\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.08767352 Acc: 0.96221662\n",
      "test Loss: 0.04031894 Acc: 0.98792757\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.08928314 Acc: 0.96473552\n",
      "test Loss: 0.03994044 Acc: 0.98792757\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.09779617 Acc: 0.95869018\n",
      "test Loss: 0.04264261 Acc: 0.98591549\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.09368320 Acc: 0.95919395\n",
      "test Loss: 0.04009271 Acc: 0.98993964\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.09532399 Acc: 0.96221662\n",
      "test Loss: 0.04241847 Acc: 0.98591549\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.09933352 Acc: 0.95465995\n",
      "test Loss: 0.04182215 Acc: 0.98792757\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.09605901 Acc: 0.96171285\n",
      "test Loss: 0.04180106 Acc: 0.98792757\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.10177327 Acc: 0.95163728\n",
      "test Loss: 0.03962126 Acc: 0.98792757\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.09334901 Acc: 0.95869018\n",
      "test Loss: 0.04158562 Acc: 0.98591549\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.08897327 Acc: 0.96423174\n",
      "test Loss: 0.04103132 Acc: 0.98993964\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.08745507 Acc: 0.96322418\n",
      "test Loss: 0.04168635 Acc: 0.98993964\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.10571173 Acc: 0.95566751\n",
      "test Loss: 0.04167904 Acc: 0.98591549\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.09157517 Acc: 0.95919395\n",
      "test Loss: 0.04119676 Acc: 0.98792757\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.10269385 Acc: 0.95566751\n",
      "test Loss: 0.04309042 Acc: 0.98591549\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.10206170 Acc: 0.95969773\n",
      "test Loss: 0.04282187 Acc: 0.98591549\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.08835728 Acc: 0.96775819\n",
      "test Loss: 0.04072390 Acc: 0.98792757\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.09746281 Acc: 0.95667506\n",
      "test Loss: 0.04113522 Acc: 0.98993964\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.10035344 Acc: 0.95919395\n",
      "test Loss: 0.04090674 Acc: 0.98993964\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.08413162 Acc: 0.96473552\n",
      "test Loss: 0.04100701 Acc: 0.98792757\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.10766874 Acc: 0.95617128\n",
      "test Loss: 0.04159334 Acc: 0.98792757\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.10880769 Acc: 0.95214106\n",
      "test Loss: 0.04314487 Acc: 0.98390342\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.09210869 Acc: 0.96171285\n",
      "test Loss: 0.03982382 Acc: 0.98792757\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.08504287 Acc: 0.96473552\n",
      "test Loss: 0.04051655 Acc: 0.98792757\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.09369713 Acc: 0.95717884\n",
      "test Loss: 0.04260279 Acc: 0.98390342\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.09493990 Acc: 0.95969773\n",
      "test Loss: 0.04037601 Acc: 0.98591549\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.09170151 Acc: 0.96372796\n",
      "test Loss: 0.04182649 Acc: 0.98792757\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.09365863 Acc: 0.95969773\n",
      "test Loss: 0.03911554 Acc: 0.98993964\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.08841820 Acc: 0.96523929\n",
      "test Loss: 0.04015986 Acc: 0.98993964\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.09421795 Acc: 0.95768262\n",
      "test Loss: 0.04077415 Acc: 0.98993964\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.09684077 Acc: 0.96020151\n",
      "test Loss: 0.04045930 Acc: 0.98792757\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.09882965 Acc: 0.95667506\n",
      "test Loss: 0.03978874 Acc: 0.98792757\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.08985040 Acc: 0.96574307\n",
      "test Loss: 0.03873517 Acc: 0.98792757\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.09427245 Acc: 0.95365239\n",
      "test Loss: 0.04001925 Acc: 0.98792757\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.10069947 Acc: 0.96120907\n",
      "test Loss: 0.04023022 Acc: 0.98993964\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.09628065 Acc: 0.95617128\n",
      "test Loss: 0.04231456 Acc: 0.98591549\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.09514780 Acc: 0.96272040\n",
      "test Loss: 0.04026014 Acc: 0.98792757\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.08195732 Acc: 0.96523929\n",
      "test Loss: 0.03807767 Acc: 0.98993964\n",
      "New best model found!\n",
      "New record loss: 0.03807767044369831, previous record loss: 0.03822064930451303\n",
      "New record loss is SAVED: 0.03807767044369831\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.09506077 Acc: 0.95969773\n",
      "test Loss: 0.03851503 Acc: 0.98993964\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.10073607 Acc: 0.95566751\n",
      "test Loss: 0.04016825 Acc: 0.98792757\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.08357264 Acc: 0.96272040\n",
      "test Loss: 0.04022366 Acc: 0.98792757\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.09816357 Acc: 0.96070529\n",
      "test Loss: 0.04289472 Acc: 0.98591549\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.08349783 Acc: 0.96423174\n",
      "test Loss: 0.04033576 Acc: 0.98993964\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.11254391 Acc: 0.95415617\n",
      "test Loss: 0.04137100 Acc: 0.98792757\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.09674604 Acc: 0.96020151\n",
      "test Loss: 0.04173566 Acc: 0.98993964\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.10422693 Acc: 0.96272040\n",
      "test Loss: 0.04100105 Acc: 0.98792757\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.08675703 Acc: 0.96574307\n",
      "test Loss: 0.04206904 Acc: 0.98591549\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.10406450 Acc: 0.95869018\n",
      "test Loss: 0.04131242 Acc: 0.98591549\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.09016541 Acc: 0.96070529\n",
      "test Loss: 0.04201250 Acc: 0.98591549\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.09137228 Acc: 0.95818640\n",
      "test Loss: 0.04121981 Acc: 0.98792757\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.09414838 Acc: 0.95869018\n",
      "test Loss: 0.03974707 Acc: 0.98993964\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.07855367 Acc: 0.97078086\n",
      "test Loss: 0.03993527 Acc: 0.98993964\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.08375140 Acc: 0.96926952\n",
      "test Loss: 0.04149586 Acc: 0.98792757\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.08276227 Acc: 0.96473552\n",
      "test Loss: 0.03990290 Acc: 0.98993964\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.09590160 Acc: 0.96171285\n",
      "test Loss: 0.03950338 Acc: 0.98792757\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.08013797 Acc: 0.97078086\n",
      "test Loss: 0.04162212 Acc: 0.98591549\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.11163058 Acc: 0.94458438\n",
      "test Loss: 0.04288166 Acc: 0.98792757\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.08955684 Acc: 0.95717884\n",
      "test Loss: 0.04076835 Acc: 0.98792757\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.08073465 Acc: 0.96574307\n",
      "test Loss: 0.03846272 Acc: 0.98993964\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.09776885 Acc: 0.95919395\n",
      "test Loss: 0.03871888 Acc: 0.98993964\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.09567448 Acc: 0.95869018\n",
      "test Loss: 0.03885241 Acc: 0.98792757\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.08436771 Acc: 0.96675063\n",
      "test Loss: 0.04134129 Acc: 0.98591549\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.09094935 Acc: 0.96171285\n",
      "test Loss: 0.04149829 Acc: 0.98792757\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.09256903 Acc: 0.95919395\n",
      "test Loss: 0.04109286 Acc: 0.98591549\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.08830267 Acc: 0.96775819\n",
      "test Loss: 0.04212601 Acc: 0.98591549\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.10632384 Acc: 0.95415617\n",
      "test Loss: 0.04027466 Acc: 0.98993964\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.10475059 Acc: 0.95012594\n",
      "test Loss: 0.03973154 Acc: 0.98993964\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.09629501 Acc: 0.95768262\n",
      "test Loss: 0.04026728 Acc: 0.98792757\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.10351531 Acc: 0.95415617\n",
      "test Loss: 0.03924582 Acc: 0.98993964\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.09035768 Acc: 0.96523929\n",
      "test Loss: 0.04092418 Acc: 0.98792757\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.09344722 Acc: 0.96322418\n",
      "test Loss: 0.03948968 Acc: 0.98993964\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.10172839 Acc: 0.95214106\n",
      "test Loss: 0.04114640 Acc: 0.98792757\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.09528437 Acc: 0.95818640\n",
      "test Loss: 0.04295922 Acc: 0.98591549\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.08286118 Acc: 0.96775819\n",
      "test Loss: 0.03820048 Acc: 0.98792757\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.07354854 Acc: 0.97329975\n",
      "test Loss: 0.04044349 Acc: 0.98792757\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.10741890 Acc: 0.95818640\n",
      "test Loss: 0.03991466 Acc: 0.98993964\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.08568483 Acc: 0.96272040\n",
      "test Loss: 0.03919829 Acc: 0.98792757\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.08818561 Acc: 0.96523929\n",
      "test Loss: 0.03978381 Acc: 0.98792757\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.08392728 Acc: 0.96624685\n",
      "test Loss: 0.04132269 Acc: 0.98792757\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.10333052 Acc: 0.95969773\n",
      "test Loss: 0.04008297 Acc: 0.98792757\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.09759667 Acc: 0.96020151\n",
      "test Loss: 0.03899949 Acc: 0.98792757\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.08851776 Acc: 0.96322418\n",
      "test Loss: 0.04022877 Acc: 0.98792757\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.09051792 Acc: 0.95969773\n",
      "test Loss: 0.04045187 Acc: 0.98792757\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.09889535 Acc: 0.95919395\n",
      "test Loss: 0.03996453 Acc: 0.98792757\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.07590853 Acc: 0.97078086\n",
      "test Loss: 0.03967335 Acc: 0.98792757\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.09374830 Acc: 0.95465995\n",
      "test Loss: 0.03955001 Acc: 0.98993964\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.09455129 Acc: 0.96221662\n",
      "test Loss: 0.04010614 Acc: 0.98792757\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.09048751 Acc: 0.96473552\n",
      "test Loss: 0.03942262 Acc: 0.98993964\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.08302367 Acc: 0.96523929\n",
      "test Loss: 0.03986816 Acc: 0.98792757\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.09833107 Acc: 0.96272040\n",
      "test Loss: 0.04170213 Acc: 0.98993964\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.09649213 Acc: 0.95869018\n",
      "test Loss: 0.04259227 Acc: 0.98591549\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.09485868 Acc: 0.96322418\n",
      "test Loss: 0.04146929 Acc: 0.98591549\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.08053077 Acc: 0.96624685\n",
      "test Loss: 0.04079680 Acc: 0.98591549\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.08298648 Acc: 0.96423174\n",
      "test Loss: 0.03864865 Acc: 0.98993964\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.08426356 Acc: 0.96675063\n",
      "test Loss: 0.04113049 Acc: 0.98792757\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.08897702 Acc: 0.96372796\n",
      "test Loss: 0.04057172 Acc: 0.98792757\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.08926026 Acc: 0.95969773\n",
      "test Loss: 0.04183267 Acc: 0.98792757\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.09440558 Acc: 0.95768262\n",
      "test Loss: 0.04087278 Acc: 0.98792757\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.10367293 Acc: 0.95566751\n",
      "test Loss: 0.03930971 Acc: 0.98792757\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.09548549 Acc: 0.96171285\n",
      "test Loss: 0.03895457 Acc: 0.98993964\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.08865970 Acc: 0.95919395\n",
      "test Loss: 0.03873434 Acc: 0.98993964\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.09725054 Acc: 0.95969773\n",
      "test Loss: 0.04163542 Acc: 0.98591549\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.10134984 Acc: 0.95667506\n",
      "test Loss: 0.04211901 Acc: 0.98993964\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.10311472 Acc: 0.95969773\n",
      "test Loss: 0.04093114 Acc: 0.98993964\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.10144030 Acc: 0.95969773\n",
      "test Loss: 0.04169674 Acc: 0.98792757\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.08803761 Acc: 0.96322418\n",
      "test Loss: 0.04329963 Acc: 0.98591549\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.09408374 Acc: 0.96171285\n",
      "test Loss: 0.04364800 Acc: 0.98591549\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.09533976 Acc: 0.96120907\n",
      "test Loss: 0.04094638 Acc: 0.98993964\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.08164107 Acc: 0.97027708\n",
      "test Loss: 0.04077954 Acc: 0.98993964\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.08939787 Acc: 0.96120907\n",
      "test Loss: 0.03867157 Acc: 0.98993964\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "train Loss: 0.08815385 Acc: 0.96423174\n",
      "test Loss: 0.04163741 Acc: 0.98792757\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.09807262 Acc: 0.95969773\n",
      "test Loss: 0.03902927 Acc: 0.98993964\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.09490948 Acc: 0.95516373\n",
      "test Loss: 0.04173056 Acc: 0.98993964\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.08266403 Acc: 0.96775819\n",
      "test Loss: 0.04231578 Acc: 0.98591549\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.09024009 Acc: 0.96372796\n",
      "test Loss: 0.04068700 Acc: 0.98792757\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.08414354 Acc: 0.96523929\n",
      "test Loss: 0.04172847 Acc: 0.98792757\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.10025163 Acc: 0.96070529\n",
      "test Loss: 0.04250009 Acc: 0.98591549\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.10151107 Acc: 0.95869018\n",
      "test Loss: 0.04236420 Acc: 0.98591549\n",
      "\n",
      "Training complete in 53m 11s\n",
      "Best val Acc: 0.98993964 Best val loss: 0.03807767\n"
     ]
    }
   ],
   "source": [
    "CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CT/weights/TResNet_Medium_Covid-19.pth'\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = 200,\n",
    "                                                 checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
