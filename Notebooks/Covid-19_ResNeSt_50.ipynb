{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dEaGqShwJKT"
   },
   "source": [
    "# Trong đại dịch Covid-19 có nguồn gốc từ Wuhan, Trung Quốc đã làm ảnh hưởng tới cuộc sống của nhân loại, cướp đi sinh mạng của ít nhất 200.000 người vô tội và sẽ còn tiếp tục tăng trong thời gian tới.\n",
    "## Để phục vụ công tác chẩn đoán bệnh, các nhà khoa học đã tìm cách áp dụng trí thông minh nhân tạo vào trong việc xử lí và chẩn đoán ảnh CT và X quang chụp phổi để đánh giá tổn thương và phân loại viêm phổi do các nguyên nhân khác nhau, trong đó có Covid-19.\n",
    "## Trong bài này, mình sử dụng dataset tại đây: https://covidresearch.ai/datasets/dataset?id=2. Theo như tìm hiểu về cơ sở dữ liệu này, có lẽ nó được tiếp thu từ 2 nghiên cứu trước đó là bài báo này https://arxiv.org/abs/2003.11597 (địa chỉ github: https://github.com/ieee8023/covid-chestxray-dataset) và bài báo này https://arxiv.org/abs/2003.09871 (https://github.com/lindawangg/COVID-Net).\n",
    "## Gần đây có bài báo công bố sử dụng mạng EfficientNet (bài báo về mạng tại đây https://arxiv.org/pdf/1905.11946.pdf) để chẩn đoán dataset này cho kết quả có độ nhạy và độ đặc hiệu cao hơn hẳn các kết quả trước đó. Các bạn có thể tham khảo bài báo này tại đây: https://arxiv.org/pdf/2004.05717.pdf. Kết quả bài báo chỉ ra rằng họ đã thêm vào mạng EfficientNet_B0 một số lớp để cải thiện khả năng phân loại. Tuy nhiên bài báo sử dụng Framework là Keras, còn trong bài lặp lại thí nghiệm này, mình sử dụng Framework là PyTorch với đóng góp rất lớn của anh Ross Wightman khi xây dựng các mạng thần kinh tích chập sâu cho công việc phân loại ảnh (các bạn có thể tham khảo code tại đây https://github.com/rwightman/pytorch-image-models).\n",
    "### Bên cạnh việc sử dụng Framework khác với bài báo gốc, mình cũng có 1 số thay đổi như mình dùng hàm tối ưu là SGD thay vì ADAM, và mình bổ thêm kĩ thuật Augmentation (ở đây mình dùng thêm kĩ thuật RandAugmentation tại bài báo này https://arxiv.org/abs/1909.13719) để nâng cao độ chính xác.\n",
    "### Mình cũng đã thử huấn luyện dataset này với các mạng khác nhau, tuy nhiên kết quả phân loại có lẽ vẫn hiệu quả nhất với mạng EfficientNet_B0.\n",
    "### Tuy nhiên, để mô hình này có thể sử dụng trong thực tiễn, chắc chắn cần phải tiến hành internal và external validity qua nhiều bước khác nhau. Thêm vào đó, chúng ta hoàn toàn có thể nghĩ đến kĩ thuật ensemble voting để tăng tính chính xác cho công cụ chẩn đoán!\n",
    "# For fun, mình xây dựng thử nền tảng web dùng cho chẩn đoán các ảnh X quang vùng ngực xem bệnh nhân có nhiễm Covid-19 hay không. Các bạn có thể tham khảo tại địa chỉ github của minh [https://github.com/linhduongtuan/Covid-19_Xray_Classifier/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from randaugment import RandAugment, ImageNetPolicy, Cutout\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID', 'non-COVID']\n",
      "{'train': 1985, 'test': 497}\n",
      "cuda:1\n",
      "{0: 'COVID', 1: 'non-COVID'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/linh/.conda/envs/CV/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/linh/.conda/envs/CV/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/linh/.conda/envs/CV/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/linh/.conda/envs/CV/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 3, 224, 224])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/linh/Downloads/Covid-19_CT'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/test'\n",
    "\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(),\n",
    "        ImageNetPolicy(),\n",
    "        Cutout(size=16),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "batch_size = 70\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4, pin_memory = True)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['train'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['test']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 20, cat_to_name)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 20, cat_to_name)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "#model = timm.create_model('resnet50', pretrain|ed=True)\n",
    "model = timm.create_model('resnest50d', pretrained=True)\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "model.fc #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28064954\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                                 #('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, 2)),\n",
    "\t\t\t\t\t\t\t\t ('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "model.classifier = classifier\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.01,momentum=0.9,\n",
    "                      nesterov=True,\n",
    "                      weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "#show our model architechture and send to GPU\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(count)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_loss < best_loss:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record loss: {epoch_loss}, previous record loss: {best_loss}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record loss is SAVED: {epoch_loss}')\n",
    "\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded\n",
      "Val loss: 0.027919416733708766, Val accuracy: 0.9939637826961771\n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.11873819 Acc: 0.95113350\n",
      "test Loss: 0.03371414 Acc: 0.98993964\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.12630497 Acc: 0.94760705\n",
      "test Loss: 0.03310223 Acc: 0.98591549\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.12300059 Acc: 0.94962217\n",
      "test Loss: 0.03905966 Acc: 0.98591549\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.12591866 Acc: 0.94408060\n",
      "test Loss: 0.03992889 Acc: 0.98792757\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.14156102 Acc: 0.93853904\n",
      "test Loss: 0.04083893 Acc: 0.98591549\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.12907196 Acc: 0.94156171\n",
      "test Loss: 0.02819916 Acc: 0.98993964\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.12903143 Acc: 0.94760705\n",
      "test Loss: 0.04440769 Acc: 0.98993964\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.10883547 Acc: 0.95717884\n",
      "test Loss: 0.05508643 Acc: 0.98792757\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.11423605 Acc: 0.94458438\n",
      "test Loss: 0.04954493 Acc: 0.98792757\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.11328910 Acc: 0.94911839\n",
      "test Loss: 0.03402218 Acc: 0.98792757\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.13694646 Acc: 0.93904282\n",
      "test Loss: 0.04858624 Acc: 0.98792757\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.11878616 Acc: 0.95264484\n",
      "test Loss: 0.05032468 Acc: 0.98993964\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.11167383 Acc: 0.95314861\n",
      "test Loss: 0.04329854 Acc: 0.98993964\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.12294083 Acc: 0.95214106\n",
      "test Loss: 0.03879493 Acc: 0.98993964\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.11750227 Acc: 0.95012594\n",
      "test Loss: 0.05573037 Acc: 0.98390342\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.13000265 Acc: 0.93954660\n",
      "test Loss: 0.02766322 Acc: 0.98993964\n",
      "New best model found!\n",
      "New record loss: 0.027663217268588634, previous record loss: 0.027919416733708766\n",
      "New record loss is SAVED: 0.027663217268588634\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.11257760 Acc: 0.95163728\n",
      "test Loss: 0.02800579 Acc: 0.98993964\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.12955173 Acc: 0.94559194\n",
      "test Loss: 0.04771653 Acc: 0.98993964\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.10926531 Acc: 0.95516373\n",
      "test Loss: 0.03769712 Acc: 0.98993964\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.11921643 Acc: 0.95264484\n",
      "test Loss: 0.05732988 Acc: 0.98792757\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.11670784 Acc: 0.95062972\n",
      "test Loss: 0.04649465 Acc: 0.98993964\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.10785136 Acc: 0.95516373\n",
      "test Loss: 0.04747388 Acc: 0.98792757\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.11972568 Acc: 0.95214106\n",
      "test Loss: 0.04646639 Acc: 0.98390342\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.12755837 Acc: 0.94206549\n",
      "test Loss: 0.04105990 Acc: 0.98792757\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.12767773 Acc: 0.94256927\n",
      "test Loss: 0.04567677 Acc: 0.98993964\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.11561273 Acc: 0.94962217\n",
      "test Loss: 0.04026905 Acc: 0.98993964\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.11975154 Acc: 0.94559194\n",
      "test Loss: 0.03745707 Acc: 0.98993964\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.11934343 Acc: 0.95214106\n",
      "test Loss: 0.03649878 Acc: 0.98792757\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.11028344 Acc: 0.95365239\n",
      "test Loss: 0.04532269 Acc: 0.98591549\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.09511653 Acc: 0.95566751\n",
      "test Loss: 0.04274357 Acc: 0.98993964\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.11080711 Acc: 0.94659950\n",
      "test Loss: 0.04190477 Acc: 0.98993964\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.12540770 Acc: 0.94861461\n",
      "test Loss: 0.04299252 Acc: 0.98792757\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.12265142 Acc: 0.94559194\n",
      "test Loss: 0.04220100 Acc: 0.98792757\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.11623297 Acc: 0.94861461\n",
      "test Loss: 0.03702041 Acc: 0.98993964\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.11697554 Acc: 0.94559194\n",
      "test Loss: 0.04149834 Acc: 0.98591549\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.11879635 Acc: 0.94911839\n",
      "test Loss: 0.04669338 Acc: 0.98591549\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.11494733 Acc: 0.95062972\n",
      "test Loss: 0.04140603 Acc: 0.98591549\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.11600399 Acc: 0.94659950\n",
      "test Loss: 0.04283615 Acc: 0.98390342\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.10916136 Acc: 0.95113350\n",
      "test Loss: 0.04520260 Acc: 0.98390342\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.11320225 Acc: 0.94710327\n",
      "test Loss: 0.04201505 Acc: 0.98792757\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.11675559 Acc: 0.94307305\n",
      "test Loss: 0.04818149 Acc: 0.98591549\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.12195406 Acc: 0.94861461\n",
      "test Loss: 0.04856369 Acc: 0.98591549\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.10891739 Acc: 0.95566751\n",
      "test Loss: 0.04189406 Acc: 0.98792757\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.11648438 Acc: 0.94760705\n",
      "test Loss: 0.04354971 Acc: 0.98591549\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.11281587 Acc: 0.95062972\n",
      "test Loss: 0.04459640 Acc: 0.98993964\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.10082774 Acc: 0.95365239\n",
      "test Loss: 0.04647008 Acc: 0.98993964\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.11947238 Acc: 0.94659950\n",
      "test Loss: 0.04456285 Acc: 0.98993964\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.11112672 Acc: 0.95062972\n",
      "test Loss: 0.04389270 Acc: 0.98993964\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.10934141 Acc: 0.95566751\n",
      "test Loss: 0.04322232 Acc: 0.98591549\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.11727860 Acc: 0.95012594\n",
      "test Loss: 0.05299185 Acc: 0.98792757\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.10667625 Acc: 0.95667506\n",
      "test Loss: 0.04268122 Acc: 0.98993964\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.11765371 Acc: 0.94357683\n",
      "test Loss: 0.04571147 Acc: 0.98993964\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.09444148 Acc: 0.96221662\n",
      "test Loss: 0.04661469 Acc: 0.98390342\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.09546350 Acc: 0.96221662\n",
      "test Loss: 0.04650629 Acc: 0.98792757\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.12569878 Acc: 0.94760705\n",
      "test Loss: 0.03957953 Acc: 0.98993964\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.11451510 Acc: 0.94962217\n",
      "test Loss: 0.04285148 Acc: 0.98993964\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.10538873 Acc: 0.96020151\n",
      "test Loss: 0.03931102 Acc: 0.98792757\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.11021758 Acc: 0.95113350\n",
      "test Loss: 0.03936461 Acc: 0.99195171\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.11749952 Acc: 0.94357683\n",
      "test Loss: 0.04091582 Acc: 0.98792757\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.11046822 Acc: 0.95163728\n",
      "test Loss: 0.04434406 Acc: 0.98792757\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.10441963 Acc: 0.95214106\n",
      "test Loss: 0.04114285 Acc: 0.98993964\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.10844093 Acc: 0.95012594\n",
      "test Loss: 0.04219180 Acc: 0.98993964\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.10952736 Acc: 0.95365239\n",
      "test Loss: 0.04042687 Acc: 0.99195171\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.10021112 Acc: 0.95919395\n",
      "test Loss: 0.04323136 Acc: 0.98591549\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.09495517 Acc: 0.96221662\n",
      "test Loss: 0.04313528 Acc: 0.98993964\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.10472341 Acc: 0.95365239\n",
      "test Loss: 0.04312098 Acc: 0.99195171\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.10055557 Acc: 0.95969773\n",
      "test Loss: 0.04424843 Acc: 0.98993964\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.10854200 Acc: 0.94911839\n",
      "test Loss: 0.04338079 Acc: 0.99195171\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.10622681 Acc: 0.95465995\n",
      "test Loss: 0.04170937 Acc: 0.98792757\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.10776210 Acc: 0.96020151\n",
      "test Loss: 0.03543261 Acc: 0.98993964\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.09456203 Acc: 0.95869018\n",
      "test Loss: 0.03873526 Acc: 0.98993964\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.10860369 Acc: 0.95717884\n",
      "test Loss: 0.03837197 Acc: 0.99195171\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.12015689 Acc: 0.94911839\n",
      "test Loss: 0.04253805 Acc: 0.98993964\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.10806172 Acc: 0.95365239\n",
      "test Loss: 0.04496104 Acc: 0.99195171\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.09997640 Acc: 0.95717884\n",
      "test Loss: 0.04029896 Acc: 0.98993964\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.11179336 Acc: 0.94962217\n",
      "test Loss: 0.04674430 Acc: 0.98993964\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.10691467 Acc: 0.95617128\n",
      "test Loss: 0.04446963 Acc: 0.98993964\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.11170621 Acc: 0.95214106\n",
      "test Loss: 0.04926667 Acc: 0.98993964\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.11222328 Acc: 0.95012594\n",
      "test Loss: 0.04590061 Acc: 0.99195171\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.09690552 Acc: 0.96020151\n",
      "test Loss: 0.04141376 Acc: 0.99195171\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.09699392 Acc: 0.95818640\n",
      "test Loss: 0.04070397 Acc: 0.98993964\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.10259719 Acc: 0.95566751\n",
      "test Loss: 0.04241445 Acc: 0.98993964\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.11895858 Acc: 0.94811083\n",
      "test Loss: 0.04575498 Acc: 0.99195171\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.11984361 Acc: 0.95163728\n",
      "test Loss: 0.04375055 Acc: 0.98993964\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.09678138 Acc: 0.96322418\n",
      "test Loss: 0.04155266 Acc: 0.99195171\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.10654102 Acc: 0.95516373\n",
      "test Loss: 0.04673334 Acc: 0.98993964\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.11044741 Acc: 0.95214106\n",
      "test Loss: 0.04209889 Acc: 0.98792757\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.09828172 Acc: 0.95768262\n",
      "test Loss: 0.04359554 Acc: 0.98993964\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.10088465 Acc: 0.95768262\n",
      "test Loss: 0.04449630 Acc: 0.99195171\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.11165282 Acc: 0.95415617\n",
      "test Loss: 0.04609059 Acc: 0.99195171\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.10850565 Acc: 0.95214106\n",
      "test Loss: 0.04430760 Acc: 0.99195171\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.11819182 Acc: 0.94559194\n",
      "test Loss: 0.04728216 Acc: 0.98792757\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.09883288 Acc: 0.96221662\n",
      "test Loss: 0.04275158 Acc: 0.98993964\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.11210342 Acc: 0.95163728\n",
      "test Loss: 0.04404243 Acc: 0.98993964\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.09998438 Acc: 0.95415617\n",
      "test Loss: 0.04387821 Acc: 0.98792757\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.12106034 Acc: 0.94609572\n",
      "test Loss: 0.04807538 Acc: 0.98792757\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.11051965 Acc: 0.95113350\n",
      "test Loss: 0.03844060 Acc: 0.98993964\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.11310139 Acc: 0.94861461\n",
      "test Loss: 0.04071795 Acc: 0.98993964\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.10838192 Acc: 0.95919395\n",
      "test Loss: 0.04390203 Acc: 0.99195171\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.11050970 Acc: 0.95214106\n",
      "test Loss: 0.04309097 Acc: 0.98993964\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.10456650 Acc: 0.95717884\n",
      "test Loss: 0.04143028 Acc: 0.98993964\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.11549844 Acc: 0.95113350\n",
      "test Loss: 0.04294445 Acc: 0.99195171\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.11101211 Acc: 0.95566751\n",
      "test Loss: 0.04641276 Acc: 0.99195171\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.09877353 Acc: 0.95667506\n",
      "test Loss: 0.04753077 Acc: 0.98993964\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.11198114 Acc: 0.94861461\n",
      "test Loss: 0.04599681 Acc: 0.98993964\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.10759366 Acc: 0.95365239\n",
      "test Loss: 0.04181654 Acc: 0.98792757\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.11530919 Acc: 0.94861461\n",
      "test Loss: 0.04435366 Acc: 0.99195171\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.10021537 Acc: 0.95566751\n",
      "test Loss: 0.04317376 Acc: 0.99195171\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.10432340 Acc: 0.96120907\n",
      "test Loss: 0.04068764 Acc: 0.98993964\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.10275906 Acc: 0.95516373\n",
      "test Loss: 0.04411314 Acc: 0.98993964\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.09956896 Acc: 0.96020151\n",
      "test Loss: 0.04299791 Acc: 0.99195171\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.10386054 Acc: 0.95768262\n",
      "test Loss: 0.04455636 Acc: 0.99195171\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.10125520 Acc: 0.95818640\n",
      "test Loss: 0.04500479 Acc: 0.99195171\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.10659973 Acc: 0.95012594\n",
      "test Loss: 0.04451377 Acc: 0.98993964\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.10884707 Acc: 0.95415617\n",
      "test Loss: 0.04405170 Acc: 0.98993964\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.10393519 Acc: 0.95768262\n",
      "test Loss: 0.04313089 Acc: 0.98993964\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.09855952 Acc: 0.95969773\n",
      "test Loss: 0.04303624 Acc: 0.98792757\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.10203947 Acc: 0.95818640\n",
      "test Loss: 0.04135931 Acc: 0.98993964\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.10530538 Acc: 0.95818640\n",
      "test Loss: 0.04557103 Acc: 0.99195171\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.11620605 Acc: 0.95667506\n",
      "test Loss: 0.04348452 Acc: 0.98993964\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.11391650 Acc: 0.95163728\n",
      "test Loss: 0.04421250 Acc: 0.98993964\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.11139479 Acc: 0.95314861\n",
      "test Loss: 0.04493946 Acc: 0.98993964\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.09636567 Acc: 0.95717884\n",
      "test Loss: 0.04826051 Acc: 0.98792757\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.09996203 Acc: 0.95415617\n",
      "test Loss: 0.04316359 Acc: 0.98993964\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.10370578 Acc: 0.95617128\n",
      "test Loss: 0.04243207 Acc: 0.98993964\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.11498937 Acc: 0.95214106\n",
      "test Loss: 0.04376410 Acc: 0.98993964\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.12130127 Acc: 0.94659950\n",
      "test Loss: 0.03943680 Acc: 0.98993964\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.11080649 Acc: 0.95415617\n",
      "test Loss: 0.04549718 Acc: 0.99195171\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.10749522 Acc: 0.95516373\n",
      "test Loss: 0.04720862 Acc: 0.99195171\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.10843696 Acc: 0.95465995\n",
      "test Loss: 0.04426947 Acc: 0.98993964\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.10673238 Acc: 0.95768262\n",
      "test Loss: 0.04054575 Acc: 0.98993964\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.11226695 Acc: 0.95214106\n",
      "test Loss: 0.04880759 Acc: 0.99195171\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.11139103 Acc: 0.95214106\n",
      "test Loss: 0.04496048 Acc: 0.98993964\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.11553588 Acc: 0.94962217\n",
      "test Loss: 0.04200896 Acc: 0.99195171\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.10659505 Acc: 0.95566751\n",
      "test Loss: 0.04708744 Acc: 0.99195171\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.09731621 Acc: 0.96070529\n",
      "test Loss: 0.03996171 Acc: 0.98993964\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.11290679 Acc: 0.95465995\n",
      "test Loss: 0.04195513 Acc: 0.99195171\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.09370985 Acc: 0.96826196\n",
      "test Loss: 0.04269507 Acc: 0.98792757\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.10832753 Acc: 0.95062972\n",
      "test Loss: 0.04383639 Acc: 0.99195171\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.11607518 Acc: 0.95062972\n",
      "test Loss: 0.04495431 Acc: 0.99195171\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.10195204 Acc: 0.95667506\n",
      "test Loss: 0.04254733 Acc: 0.99195171\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.11428714 Acc: 0.95264484\n",
      "test Loss: 0.04620738 Acc: 0.99195171\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.09642107 Acc: 0.95969773\n",
      "test Loss: 0.04421382 Acc: 0.99195171\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.10986565 Acc: 0.95264484\n",
      "test Loss: 0.04289838 Acc: 0.98792757\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.10455983 Acc: 0.95163728\n",
      "test Loss: 0.04623853 Acc: 0.99195171\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.11084596 Acc: 0.95062972\n",
      "test Loss: 0.04723312 Acc: 0.98993964\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.10979133 Acc: 0.95113350\n",
      "test Loss: 0.04559043 Acc: 0.98993964\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.10304477 Acc: 0.95617128\n",
      "test Loss: 0.04522387 Acc: 0.98993964\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.10276105 Acc: 0.95919395\n",
      "test Loss: 0.04662314 Acc: 0.98792757\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.11129606 Acc: 0.95516373\n",
      "test Loss: 0.04842773 Acc: 0.99195171\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.09246429 Acc: 0.95818640\n",
      "test Loss: 0.04099058 Acc: 0.99195171\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.12061161 Acc: 0.94861461\n",
      "test Loss: 0.04477303 Acc: 0.99195171\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.10521637 Acc: 0.95516373\n",
      "test Loss: 0.04237663 Acc: 0.98993964\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.11559709 Acc: 0.95163728\n",
      "test Loss: 0.04490439 Acc: 0.98993964\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.09864753 Acc: 0.96070529\n",
      "test Loss: 0.04468691 Acc: 0.98993964\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.10194657 Acc: 0.95314861\n",
      "test Loss: 0.04210897 Acc: 0.99195171\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.10080296 Acc: 0.95768262\n",
      "test Loss: 0.04508536 Acc: 0.99195171\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.11028832 Acc: 0.95314861\n",
      "test Loss: 0.04454594 Acc: 0.98993964\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.09728141 Acc: 0.96171285\n",
      "test Loss: 0.04419794 Acc: 0.99195171\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.11244161 Acc: 0.95163728\n",
      "test Loss: 0.04272808 Acc: 0.98792757\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.09325868 Acc: 0.95919395\n",
      "test Loss: 0.04925057 Acc: 0.98993964\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.11342218 Acc: 0.95264484\n",
      "test Loss: 0.04648532 Acc: 0.98993964\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.10753234 Acc: 0.95768262\n",
      "test Loss: 0.04847383 Acc: 0.98993964\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.10608547 Acc: 0.95415617\n",
      "test Loss: 0.04617300 Acc: 0.99195171\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.11341946 Acc: 0.95214106\n",
      "test Loss: 0.04162152 Acc: 0.98993964\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.10110727 Acc: 0.96020151\n",
      "test Loss: 0.04154554 Acc: 0.98993964\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.09376647 Acc: 0.96171285\n",
      "test Loss: 0.04424741 Acc: 0.99195171\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.11543134 Acc: 0.95617128\n",
      "test Loss: 0.04406935 Acc: 0.98993964\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.09821225 Acc: 0.96020151\n",
      "test Loss: 0.04793035 Acc: 0.98792757\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.10887984 Acc: 0.95314861\n",
      "test Loss: 0.04139475 Acc: 0.98993964\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.09944120 Acc: 0.95566751\n",
      "test Loss: 0.04773345 Acc: 0.99195171\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.09861614 Acc: 0.95818640\n",
      "test Loss: 0.04783479 Acc: 0.98189135\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.11483916 Acc: 0.94962217\n",
      "test Loss: 0.05046316 Acc: 0.98993964\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.10878758 Acc: 0.95617128\n",
      "test Loss: 0.04472106 Acc: 0.98993964\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.11782267 Acc: 0.95214106\n",
      "test Loss: 0.04165014 Acc: 0.98993964\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.12814438 Acc: 0.94710327\n",
      "test Loss: 0.04312920 Acc: 0.98993964\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.10980398 Acc: 0.95415617\n",
      "test Loss: 0.04441346 Acc: 0.98591549\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.09785559 Acc: 0.95617128\n",
      "test Loss: 0.04630755 Acc: 0.98993964\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.11811189 Acc: 0.94911839\n",
      "test Loss: 0.04547606 Acc: 0.98993964\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.09941686 Acc: 0.96171285\n",
      "test Loss: 0.04057009 Acc: 0.98993964\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.10792957 Acc: 0.95617128\n",
      "test Loss: 0.04876643 Acc: 0.99195171\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.09779853 Acc: 0.95717884\n",
      "test Loss: 0.04913322 Acc: 0.99195171\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.10992260 Acc: 0.94861461\n",
      "test Loss: 0.04438189 Acc: 0.98792757\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.11719957 Acc: 0.94760705\n",
      "test Loss: 0.04165034 Acc: 0.98792757\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.10504110 Acc: 0.95465995\n",
      "test Loss: 0.04310485 Acc: 0.98993964\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.11381970 Acc: 0.94811083\n",
      "test Loss: 0.04294575 Acc: 0.98993964\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.10348137 Acc: 0.95969773\n",
      "test Loss: 0.04248526 Acc: 0.99195171\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.10993114 Acc: 0.94659950\n",
      "test Loss: 0.04166504 Acc: 0.99195171\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.09604329 Acc: 0.95516373\n",
      "test Loss: 0.04538234 Acc: 0.99195171\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.10660556 Acc: 0.95163728\n",
      "test Loss: 0.04371961 Acc: 0.98993964\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.09782472 Acc: 0.96322418\n",
      "test Loss: 0.04513801 Acc: 0.98993964\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.09808160 Acc: 0.95566751\n",
      "test Loss: 0.04443627 Acc: 0.99195171\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "train Loss: 0.10401450 Acc: 0.95163728\n",
      "test Loss: 0.04478638 Acc: 0.98993964\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.11508365 Acc: 0.95264484\n",
      "test Loss: 0.04738802 Acc: 0.98993964\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.09710842 Acc: 0.96322418\n",
      "test Loss: 0.04337744 Acc: 0.99195171\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.11050739 Acc: 0.95214106\n",
      "test Loss: 0.04362838 Acc: 0.98591549\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.10476531 Acc: 0.95415617\n",
      "test Loss: 0.04492107 Acc: 0.98993964\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.09960178 Acc: 0.95818640\n",
      "test Loss: 0.04392364 Acc: 0.98591549\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.10835529 Acc: 0.95617128\n",
      "test Loss: 0.04898027 Acc: 0.99195171\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.10336727 Acc: 0.95717884\n",
      "test Loss: 0.04712905 Acc: 0.99195171\n",
      "\n",
      "Training complete in 88m 47s\n",
      "Best val Acc: 0.98993964 Best val loss: 0.02766322\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-886ccbbffa1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                  ) \n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m torch.save({'model_state_dict': model.module.state_dict(),\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;34m'best_val_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_val_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/CV/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'module'"
     ]
    }
   ],
   "source": [
    "CHECK_POINT_PATH = '/home/linh/Downloads/Covid-19_CT/weights/ResNeST_50_Covid-19.pth'\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = 200,\n",
    "                                                 checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.module.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
